{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12486024,"sourceType":"datasetVersion","datasetId":7878862},{"sourceId":13838820,"sourceType":"datasetVersion","datasetId":8770842}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"ff3c5df1","cell_type":"markdown","source":"# MM-CTR (WWW 2025) — Notebook complet\nCe notebook te donne un pipeline **propre, robuste et extensible** pour augmenter l’AUC sur **Task1 / Task2 / Task1&2**.\n\n✅ Améliorations clés incluses :\n- **Padding row (item_id=0) fixé** (vecteur zéro) — indispensable  \n- **Teacher séquentiel (Word2Vec *ou* SASRec-lite)** sur `item_seq.parquet`  \n- **Distillation image → teacher** avec **Cosine + InfoNCE** (meilleur que MSE)\n- **Fusion teacher + student** (gating) + fallback cold-start\n- Génération `item_info_updated.parquet` **sans casser la 1ère ligne padding**\n- Entraînement CTR via **FuxiCTR** (DIN baseline) + options modèles plus forts (DCNv2 / AutoInt) pour Task1&2\n\n> ⚠️ Règles :  \n> - **Task1** : tu modifies seulement `item_emb` dans `item_info.parquet` et tu entraînes **DIN baseline** avec hyperparams limités.  \n> - **Task2** : tu dois choisir un des 4 embeddings fournis dans `item_emb.parquet`.  \n> - **Task1&2** : tu peux faire **meilleurs embeddings + meilleur modèle CTR**, mais tu dois garder les splits et ne modifier que `item_emb` dans `item_info.parquet`.\n\n---\n\n## 0) Setup\nExécute dans Kaggle.\n","metadata":{}},{"id":"a4463966-f206-413b-98ab-6c44459bfff0","cell_type":"code","source":"# =========================\n# 0) Setup (Kaggle)\n# =========================\n!pip -q install -U \"transformers>=4.41\" datasets polars pyarrow gensim tqdm scikit-learn accelerate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T20:44:12.606781Z","iopub.execute_input":"2025-12-18T20:44:12.607550Z","iopub.status.idle":"2025-12-18T20:44:42.217093Z","shell.execute_reply.started":"2025-12-18T20:44:12.607507Z","shell.execute_reply":"2025-12-18T20:44:42.216398Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m800.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.4/802.4 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf-polars-cu12 25.6.0 requires polars<1.29,>=1.25, but you have polars 1.36.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"id":"42a974c3","cell_type":"code","source":"import os, json, math, time, random\nfrom dataclasses import dataclass\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T20:44:42.218557Z","iopub.execute_input":"2025-12-18T20:44:42.218836Z","iopub.status.idle":"2025-12-18T20:44:49.706682Z","shell.execute_reply.started":"2025-12-18T20:44:42.218807Z","shell.execute_reply":"2025-12-18T20:44:49.705905Z"}},"outputs":[],"execution_count":2},{"id":"0cae33fe-facc-462f-bfd2-ffa41fef3072","cell_type":"markdown","source":"","metadata":{}},{"id":"9f52d7ed","cell_type":"markdown","source":"## 1) Config\n> Mets ici tes chemins. (Kaggle : `/kaggle/input/...` et `/kaggle/working/...`)\n","metadata":{}},{"id":"efdb366e","cell_type":"code","source":"@dataclass\nclass CFG:\n    # ---------- DATA ----------\n    DATA_ROOT: str = \"/kaggle/input/www2025-mmctr-data/MicroLens_1M_MMCTR\"\n    DATASET_ID: str = \"MicroLens_1M_x1\"\n    WORK_DIR: str = \"/kaggle/working\"\n\n    # raw files (auto)\n    ITEM_INFO: str = None\n    ITEM_SEQ: str = None\n    TRAIN: str = None\n    VALID: str = None\n    TEST: str = None\n\n    # images (auto)\n    IMG_DIR: str = None\n\n    # ---------- EMBEDDINGS ----------\n    EMB_DIM: int = 128\n    CLIP_MODEL_ID: str = \"openai/clip-vit-base-patch32\"\n\n    # teacher method: \"word2vec\" or \"sasrec\"\n    TEACHER_METHOD: str = \"word2vec\"\n\n    # Word2Vec params\n    W2V_WINDOW: int = 10\n    W2V_MIN_COUNT: int = 2\n    W2V_EPOCHS: int = 5\n\n    # SASRec-lite params\n    MAX_LEN: int = 50\n    SASREC_EPOCHS: int = 2\n    SASREC_BATCH: int = 256\n    SASREC_LR: float = 2e-3\n    SASREC_NNEG: int = 50\n\n    # student projector params\n    PROJ_HIDDEN: int = 256\n    PROJ_DROPOUT: float = 0.1\n    PROJ_EPOCHS: int = 3\n    PROJ_BATCH: int = 512\n    PROJ_LR: float = 2e-3\n    ALPHA_COS: float = 0.7\n    BETA_NCE: float = 0.3\n    TEMPERATURE: float = 0.07\n\n    # fusion params\n    USE_GATING: bool = True\n\n    # sanity/perf\n    DEVICE: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    SEED: int = 42\n\ncfg = CFG()\n\n# ----------------------------\n# Auto-wire paths (FIXED)\n# ----------------------------\ncfg.ITEM_INFO = f\"{cfg.DATA_ROOT}/{cfg.DATASET_ID}/item_info.parquet\"\ncfg.TRAIN     = f\"{cfg.DATA_ROOT}/{cfg.DATASET_ID}/train.parquet\"\ncfg.VALID     = f\"{cfg.DATA_ROOT}/{cfg.DATASET_ID}/valid.parquet\"\ncfg.TEST      = f\"{cfg.DATA_ROOT}/{cfg.DATASET_ID}/test.parquet\"\n\n# IMPORTANT: item_seq est à la racine (pas dans MicroLens_1M_x1)\ncfg.ITEM_SEQ  = f\"{cfg.DATA_ROOT}/item_seq.parquet\"\n\n# IMPORTANT: images = item_images/item_images/\ncfg.IMG_DIR   = f\"{cfg.DATA_ROOT}/item_images/item_images\"\n\nPath(cfg.WORK_DIR).mkdir(parents=True, exist_ok=True)\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nseed_everything(cfg.SEED)\n\nprint(\"Device:\", cfg.DEVICE)\nprint(\"ITEM_INFO:\", cfg.ITEM_INFO)\nprint(\"ITEM_SEQ :\", cfg.ITEM_SEQ)\nprint(\"IMG_DIR  :\", cfg.IMG_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T20:44:49.707611Z","iopub.execute_input":"2025-12-18T20:44:49.707993Z","iopub.status.idle":"2025-12-18T20:44:49.810774Z","shell.execute_reply.started":"2025-12-18T20:44:49.707969Z","shell.execute_reply":"2025-12-18T20:44:49.810131Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nITEM_INFO: /kaggle/input/www2025-mmctr-data/MicroLens_1M_MMCTR/MicroLens_1M_x1/item_info.parquet\nITEM_SEQ : /kaggle/input/www2025-mmctr-data/MicroLens_1M_MMCTR/item_seq.parquet\nIMG_DIR  : /kaggle/input/www2025-mmctr-data/MicroLens_1M_MMCTR/item_images/item_images\n","output_type":"stream"}],"execution_count":3},{"id":"130f84a5","cell_type":"markdown","source":"## 2) Load item_info + vérifier la padding row\nLa 1ère ligne de `item_info.parquet` est un **padding** et doit être conservée.\n","metadata":{}},{"id":"129d5872","cell_type":"code","source":"\nitem_info = pl.read_parquet(cfg.ITEM_INFO)\nprint(item_info.head(3))\nprint(\"Rows:\", item_info.height, \"Cols:\", item_info.columns)\n\n# Sanity padding\nfirst_item = item_info.row(0)\nprint(\"\\nFirst row item_id:\", first_item[item_info.columns.index(\"item_id\")] if \"item_id\" in item_info.columns else \"N/A\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T20:44:49.812164Z","iopub.execute_input":"2025-12-18T20:44:49.812427Z","iopub.status.idle":"2025-12-18T20:44:52.311657Z","shell.execute_reply.started":"2025-12-18T20:44:49.812406Z","shell.execute_reply":"2025-12-18T20:44:52.310975Z"}},"outputs":[{"name":"stdout","text":"shape: (3, 3)\n┌─────────┬───────────────┬─────────────────────────────────┐\n│ item_id ┆ item_tags     ┆ item_emb_d128                   │\n│ ---     ┆ ---           ┆ ---                             │\n│ i64     ┆ array[i64, 5] ┆ array[f64, 128]                 │\n╞═════════╪═══════════════╪═════════════════════════════════╡\n│ 0       ┆ [0, 0, … 0]   ┆ [0.0, 0.0, … 0.0]               │\n│ 1       ┆ [0, 0, … 1]   ┆ [-0.587725, -0.384628, … -0.05… │\n│ 2       ┆ [0, 0, … 4]   ┆ [-2.50544, 1.56058, … 0.154814… │\n└─────────┴───────────────┴─────────────────────────────────┘\nRows: 91718 Cols: ['item_id', 'item_tags', 'item_emb_d128']\n\nFirst row item_id: 0\n","output_type":"stream"}],"execution_count":4},{"id":"7d431a7e","cell_type":"markdown","source":"## 3) Charger les séquences utilisateurs (`item_seq.parquet`)\nOn essaye d’être robuste : `item_seq` peut être une liste, string JSON, ou une colonne déjà tokenisée.\n","metadata":{}},{"id":"94dd9bff-0c4b-468b-becb-955485176b32","cell_type":"code","source":"# =========================================================\n# 0) SILENCE WARNINGS + LOGS\n# =========================================================\nimport os, warnings, gc\nwarnings.filterwarnings(\"ignore\")\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\ntry:\n    from transformers.utils import logging as hf_logging\n    hf_logging.set_verbosity_error()\nexcept:\n    pass\n\n# =========================================================\n# 1) IMPORTS\n# =========================================================\nimport numpy as np\nimport polars as pl\nfrom tqdm.auto import tqdm\nfrom numba import njit\n\nimport torch\nprint(\"Polars:\", pl.__version__)\nprint(\"Torch :\", torch.__version__)\n\nfrom sklearn.decomposition import PCA\n\n# =========================================================\n# 2) PARAMÈTRES \"PLUS FORTS\" (AUC)\n# =========================================================\nSEED   = getattr(cfg, \"SEED\", 42)\nDEVICE = getattr(cfg, \"DEVICE\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# --- data sampling ---\n# On filtre par user_id%KEEP_MOD (RAM-safe), puis on group_by user_id\n# Pour +AUC: ↓KEEP_MOD (donc + de data)\nKEEP_MOD = 4     # 10=faible, 4=fort, 3=très fort (si RAM OK)\nKEEP_REM = 0\nDO_GROUPBY_USER = True\n\n# On limite le nombre d'utilisateurs uniques (après group_by) pour éviter RAM explosion\nMAX_USERS_W2V = 300_000   # 100k OK, 300k mieux, 500k si Kaggle 30GB\n\n# --- Word2Vec \"fort\" ---\nMAX_LEN_W2V = 200         # Word2Vec apprend mieux avec plus d'historique\nW2V_DIM_BIG = 256         # on apprend 256d puis PCA -> 128d\nFINAL_DIM = getattr(cfg, \"EMB_DIM\", 128)\n\nW2V_WINDOW    = 25        # 20-30 souvent bon\nW2V_MIN_COUNT = 2         # 2 augmente coverage (rare items)\nW2V_EPOCHS    = 12        # 10-15 selon temps\nW2V_NEG       = 20        # plus de negatives -> souvent mieux\nW2V_SAMPLE    = 1e-5      # moins d'agressivité que 1e-4 (garde info populaires)\n\n# pondération SG/CBOW\nALPHA_SG = 0.6\nALPHA_CBOW = 0.4\n\nnp.random.seed(SEED)\n\n# =========================================================\n# 3) LOAD item_seq (RAM-SAFE) + group_by user\n# =========================================================\ndef load_user_sequences_hash(item_seq_path: str, keep_mod: int, keep_rem: int, do_groupby: bool = True):\n    lazy = (pl.scan_parquet(item_seq_path)\n              .select([\"user_id\", \"item_seq\"])\n              .filter((pl.col(\"user_id\") % keep_mod) == keep_rem))\n    df = lazy.collect(streaming=True)\n\n    if do_groupby:\n        df = (df.group_by(\"user_id\")\n                .agg(pl.col(\"item_seq\").flatten().alias(\"item_seq\")))\n    return df\n\nseq_df = load_user_sequences_hash(cfg.ITEM_SEQ, KEEP_MOD, KEEP_REM, DO_GROUPBY_USER)\nprint(\"✅ after hash+group_by:\", seq_df.shape)\n\n# limiter le nb d'utilisateurs uniques (pour RAM/temps)\nif seq_df.height > MAX_USERS_W2V:\n    seq_df = seq_df.sample(n=MAX_USERS_W2V, seed=SEED)\n    print(\"✅ after cap MAX_USERS_W2V:\", seq_df.shape)\n\n# Conversion (sur un df limité)\nseqs = seq_df[\"item_seq\"].to_list()\ndel seq_df\ngc.collect()\nprint(\"✅ nb users(seqs):\", len(seqs))\n\n# =========================================================\n# 4) PACK en matrice X (N, MAX_LEN_W2V) + Numba clean\n# =========================================================\nX = np.zeros((len(seqs), MAX_LEN_W2V), dtype=np.int32)\n\nfor i, s in enumerate(tqdm(seqs, desc=\"Packing X (W2V)\")):\n    # remove 0, keep >0\n    tmp = [int(v) for v in s if v and int(v) > 0]\n    if len(tmp) < 2:\n        continue\n    tmp = tmp[-MAX_LEN_W2V:]\n    X[i, -len(tmp):] = np.array(tmp, dtype=np.int32)\n\ndel seqs\ngc.collect()\n\n@njit\ndef compute_valid(X):\n    n, L = X.shape\n    valid = np.zeros(n, dtype=np.uint8)\n    for i in range(n):\n        cnt = 0\n        for j in range(L):\n            if X[i, j] != 0:\n                cnt += 1\n        if cnt >= 2:\n            valid[i] = 1\n    return valid\n\n@njit\ndef compact_rows(X, valid):\n    n, L = X.shape\n    m = 0\n    for i in range(n):\n        if valid[i] == 1:\n            m += 1\n    Y = np.zeros((m, L), dtype=X.dtype)\n    k = 0\n    for i in range(n):\n        if valid[i] == 1:\n            for j in range(L):\n                Y[k, j] = X[i, j]\n            k += 1\n    return Y\n\nvalid = compute_valid(X)\nX = compact_rows(X, valid)\ndel valid\ngc.collect()\nprint(\"✅ X final:\", X.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T21:00:46.523839Z","iopub.execute_input":"2025-12-18T21:00:46.524229Z","iopub.status.idle":"2025-12-18T21:01:08.802718Z","shell.execute_reply.started":"2025-12-18T21:00:46.524191Z","shell.execute_reply":"2025-12-18T21:01:08.801913Z"}},"outputs":[{"name":"stdout","text":"Polars: 1.36.1\nTorch : 2.8.0+cu126\n✅ after hash+group_by: (250000, 2)\n✅ nb users(seqs): 250000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Packing X (W2V):   0%|          | 0/250000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74d19cfb07cf4beb92aef728fc89b3e5"}},"metadata":{}},{"name":"stdout","text":"✅ X final: (250000, 200)\n","output_type":"stream"}],"execution_count":9},{"id":"5b22176c-5483-4501-8c7f-a1e696d129e9","cell_type":"markdown","source":"# 4) Teacher embeddings (séquences → 128d)\nDeux choix :\n- **Word2Vec** (rapide, baseline)\n- **SASRec-lite** (transformer séquentiel, souvent meilleur pour AUC)\n\nChoisis via `cfg.TEACHER_METHOD == Word2Vec`.","metadata":{}},{"id":"f2c603fe","cell_type":"code","source":"# =========================================================\n# 5) Word2Vec++ : SG + CBOW en 256d (iterator RAM-safe)\n# =========================================================\nclass XSentenceIterator:\n    def __init__(self, X):\n        self.X = X\n    def __iter__(self):\n        X = self.X\n        for i in range(X.shape[0]):\n            row = X[i]\n            tokens = [str(int(v)) for v in row if v != 0]\n            if len(tokens) >= 2:\n                yield tokens\n\ndef train_w2v(X, vector_size=256, sg=1):\n    from gensim.models import Word2Vec\n    it = XSentenceIterator(X)\n\n    model = Word2Vec(\n        vector_size=vector_size,\n        window=W2V_WINDOW,\n        min_count=W2V_MIN_COUNT,\n        workers=4,\n        sg=sg,                 # 1=skip-gram, 0=cbow\n        negative=W2V_NEG,\n        sample=W2V_SAMPLE,\n        epochs=W2V_EPOCHS,\n        seed=SEED\n    )\n    print(f\"➡️ build_vocab (sg={sg}) ...\")\n    model.build_vocab(it)\n\n    print(f\"➡️ train (sg={sg}) ...\")\n    model.train(it, total_examples=model.corpus_count, epochs=model.epochs)\n\n    kv = model.wv\n    out = {int(k): kv[k].astype(np.float32) for k in kv.index_to_key}\n    del model\n    gc.collect()\n    return out\n\nteacher_sg = train_w2v(X, vector_size=W2V_DIM_BIG, sg=1)\nteacher_cb = train_w2v(X, vector_size=W2V_DIM_BIG, sg=0)\n\n# =========================================================\n# 6) Combiner SG/CBOW puis PCA -> 128d\n# =========================================================\n# union des items\nall_keys = sorted(set(teacher_sg.keys()) | set(teacher_cb.keys()))\nprint(\"✅ union vocab:\", len(all_keys))\n\n# matrice [V, 256]\nM = np.zeros((len(all_keys), W2V_DIM_BIG), dtype=np.float32)\nfor i, k in enumerate(tqdm(all_keys, desc=\"Fusion SG/CBOW\")):\n    v = None\n    if k in teacher_sg and k in teacher_cb:\n        v = ALPHA_SG * teacher_sg[k] + ALPHA_CBOW * teacher_cb[k]\n    elif k in teacher_sg:\n        v = teacher_sg[k]\n    else:\n        v = teacher_cb[k]\n    M[i] = v\n\ndel teacher_sg, teacher_cb\ngc.collect()\n\nprint(\"➡️ PCA 256 ->\", FINAL_DIM)\npca = PCA(n_components=FINAL_DIM, svd_solver=\"randomized\", random_state=SEED)\nM128 = pca.fit_transform(M).astype(np.float32)\ndel M\ngc.collect()\n\nteacher = {k: M128[i] for i, k in enumerate(all_keys)}\ndel M128, all_keys\ngc.collect()\n\n# =========================================================\n# 7) Remplir les items manquants via item_tags (améliore coverage)\n# =========================================================\nitem_info_small = (pl.scan_parquet(cfg.ITEM_INFO)\n                     .select([\"item_id\", \"item_tags\"])\n                     .collect(streaming=True))\nitem_ids = item_info_small[\"item_id\"].to_list()\nitem_tags = item_info_small[\"item_tags\"].to_list()\ndel item_info_small\ngc.collect()\n\n# build tag -> (sum,count) à partir des items déjà appris\ntag_sum = {}\ntag_cnt = {}\nglobal_sum = np.zeros((FINAL_DIM,), dtype=np.float32)\nglobal_cnt = 0\n\nfor iid, tags in tqdm(zip(item_ids, item_tags), total=len(item_ids), desc=\"Tag stats\"):\n    iid = int(iid)\n    if iid == 0:\n        continue\n    v = teacher.get(iid, None)\n    if v is None:\n        continue\n    global_sum += v\n    global_cnt += 1\n    for t in tags:\n        t = int(t)\n        if t == 0:\n            continue\n        if t not in tag_sum:\n            tag_sum[t] = v.copy()\n            tag_cnt[t] = 1\n        else:\n            tag_sum[t] += v\n            tag_cnt[t] += 1\n\nglobal_mean = global_sum / max(global_cnt, 1)\n\n# impute missing\nmissing = 0\nfor iid, tags in tqdm(zip(item_ids, item_tags), total=len(item_ids), desc=\"Impute missing\"):\n    iid = int(iid)\n    if iid == 0:\n        continue\n    if iid in teacher:\n        continue\n\n    vecs = []\n    for t in tags:\n        t = int(t)\n        if t != 0 and t in tag_sum:\n            vecs.append(tag_sum[t] / tag_cnt[t])\n\n    if len(vecs) > 0:\n        v = np.mean(np.stack(vecs, axis=0), axis=0).astype(np.float32)\n        # shrinkage vers global mean (évite bruit tags rares)\n        v = 0.8 * v + 0.2 * global_mean\n    else:\n        # fallback global_mean + petit bruit\n        v = global_mean + (np.random.normal(0, 0.01, size=(FINAL_DIM,)).astype(np.float32))\n\n    teacher[iid] = v\n    missing += 1\n\nprint(\"✅ missing imputés:\", missing)\n\n# =========================================================\n# 8) Normalisation L2 (souvent meilleur pour CTR)\n# =========================================================\ndef l2_normalize(v, eps=1e-12):\n    n = float(np.sqrt((v * v).sum()))\n    if n < eps:\n        return v\n    return (v / n).astype(np.float32)\n\nfor k in list(teacher.keys()):\n    teacher[k] = l2_normalize(teacher[k])\n\n# =========================================================\n# 9) Construire matrice finale item_emb (n_items, 128)\n# =========================================================\nmax_item_id = (pl.scan_parquet(cfg.ITEM_INFO)\n                 .select(pl.col(\"item_id\").max().alias(\"m\"))\n                 .collect(streaming=True)[\"m\"][0])\nn_items = int(max_item_id) + 1\n\nemb_final = np.zeros((n_items, FINAL_DIM), dtype=np.float32)\n# padding row 0 = zeros (important)\nfor i in range(1, n_items):\n    if i in teacher:\n        emb_final[i] = teacher[i]\n    else:\n        # rarement\n        emb_final[i] = l2_normalize(global_mean.copy())\n\ncoverage = (np.count_nonzero(np.linalg.norm(emb_final[1:], axis=1) > 0) / (n_items - 1))\nprint(\"✅ n_items:\", n_items)\nprint(\"✅ coverage final:\", coverage)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T21:01:17.490143Z","iopub.execute_input":"2025-12-18T21:01:17.490531Z","iopub.status.idle":"2025-12-18T22:55:48.476882Z","shell.execute_reply.started":"2025-12-18T21:01:17.490503Z","shell.execute_reply":"2025-12-18T22:55:48.475969Z"}},"outputs":[{"name":"stdout","text":"➡️ build_vocab (sg=1) ...\n➡️ train (sg=1) ...\n➡️ build_vocab (sg=0) ...\n➡️ train (sg=0) ...\n✅ union vocab: 88688\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fusion SG/CBOW:   0%|          | 0/88688 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e77f1479df64c7c9d658e8bc1e5caf4"}},"metadata":{}},{"name":"stdout","text":"➡️ PCA 256 -> 128\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Tag stats:   0%|          | 0/91718 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b6d3c55a4184cc79236afb12fbcc5e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Impute missing:   0%|          | 0/91718 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b45b31bce2304ddbb4319941bff3a1c3"}},"metadata":{}},{"name":"stdout","text":"✅ missing imputés: 3029\n✅ n_items: 91718\n✅ coverage final: 1.0\n","output_type":"stream"}],"execution_count":10},{"id":"85cb1012-0dde-4222-baa9-2b09dc935a6a","cell_type":"code","source":"import polars as pl\nimport numpy as np\nimport gc\n\n# Lire item_info\nitem_info = pl.read_parquet(cfg.ITEM_INFO)\nprint(\"item_info:\", item_info.shape, item_info.columns)\nprint(item_info.head(2))\n\n# emb_final: numpy [n_items, 128] float32\nassert emb_final.shape[0] == item_info.height, \"n_items mismatch (doit inclure la ligne 0 padding)\"\nassert emb_final.shape[1] == 128, \"dim mismatch\"\n\n# Convertir en list[list[float]] pour Polars (col array/list)\n# ⚠️ pour éviter surcoût RAM: conversion en float32 + tolist()\nemb_list = emb_final.astype(np.float32).tolist()\n\n# Remplacer la colonne\nitem_info_new = item_info.with_columns(\n    pl.Series(\"item_emb_d128\", emb_list)\n)\n\n# Sauvegarder (dans working)\nout_path = f\"{cfg.WORK_DIR}/item_info.parquet\"\nitem_info_new.write_parquet(out_path)\nprint(\"✅ Saved:\", out_path)\n\ndel item_info, item_info_new, emb_list\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T23:18:20.242257Z","iopub.execute_input":"2025-12-18T23:18:20.242996Z","iopub.status.idle":"2025-12-18T23:18:23.637784Z","shell.execute_reply.started":"2025-12-18T23:18:20.242968Z","shell.execute_reply":"2025-12-18T23:18:23.637213Z"}},"outputs":[{"name":"stdout","text":"item_info: (91718, 3) ['item_id', 'item_tags', 'item_emb_d128']\nshape: (2, 3)\n┌─────────┬───────────────┬─────────────────────────────────┐\n│ item_id ┆ item_tags     ┆ item_emb_d128                   │\n│ ---     ┆ ---           ┆ ---                             │\n│ i64     ┆ array[i64, 5] ┆ array[f64, 128]                 │\n╞═════════╪═══════════════╪═════════════════════════════════╡\n│ 0       ┆ [0, 0, … 0]   ┆ [0.0, 0.0, … 0.0]               │\n│ 1       ┆ [0, 0, … 1]   ┆ [-0.587725, -0.384628, … -0.05… │\n└─────────┴───────────────┴─────────────────────────────────┘\n✅ Saved: /kaggle/working/item_info.parquet\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"23"},"metadata":{}}],"execution_count":11},{"id":"6fb056de-a9cd-49fd-8896-2c6f007f80dc","cell_type":"code","source":"tmp = pl.read_parquet(f\"{cfg.WORK_DIR}/item_info.parquet\")\nprint(tmp.head(2))\nprint(\"Shape:\", tmp.shape)\nprint(\"Type col item_emb_d128:\", tmp.schema[\"item_emb_d128\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T23:18:27.602597Z","iopub.execute_input":"2025-12-18T23:18:27.603378Z","iopub.status.idle":"2025-12-18T23:18:27.835091Z","shell.execute_reply.started":"2025-12-18T23:18:27.603340Z","shell.execute_reply":"2025-12-18T23:18:27.834393Z"}},"outputs":[{"name":"stdout","text":"shape: (2, 3)\n┌─────────┬───────────────┬─────────────────────────────────┐\n│ item_id ┆ item_tags     ┆ item_emb_d128                   │\n│ ---     ┆ ---           ┆ ---                             │\n│ i64     ┆ array[i64, 5] ┆ list[f64]                       │\n╞═════════╪═══════════════╪═════════════════════════════════╡\n│ 0       ┆ [0, 0, … 0]   ┆ [0.0, 0.0, … 0.0]               │\n│ 1       ┆ [0, 0, … 1]   ┆ [-0.289416, 0.232379, … 0.1086… │\n└─────────┴───────────────┴─────────────────────────────────┘\nShape: (91718, 3)\nType col item_emb_d128: List(Float64)\n","output_type":"stream"}],"execution_count":12},{"id":"e053e7d6","cell_type":"markdown","source":"# 5) CLIP image embeddings (512d)\nOn extrait des features image CLIP (512d), puis on distille vers 128d.\n","metadata":{}},{"id":"437a499f","cell_type":"code","source":"# =========================================================\n# 0) SILENCE WARNINGS + TF/XLA NOISE\n# =========================================================\nimport os, warnings, gc\nwarnings.filterwarnings(\"ignore\")\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  # réduit bruit TF/XLA si jamais présent\n\n# =========================================================\n# 1) IMPORTS\n# =========================================================\nimport numpy as np\nimport polars as pl\nfrom pathlib import Path\nfrom PIL import Image\nfrom tqdm.auto import tqdm\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\nfrom transformers import CLIPModel, CLIPImageProcessor\n\ntorch.backends.cuda.matmul.allow_tf32 = True\ntorch.backends.cudnn.benchmark = True\n\nprint(\"Device:\", cfg.DEVICE)\n\n# =========================================================\n# 2) LOAD item_info (FIX NameError)\n# =========================================================\nitem_info = pl.read_parquet(cfg.ITEM_INFO)  # ou cfg.WORK_DIR + \"/item_info.parquet\"\nprint(\"✅ item_info:\", item_info.shape, item_info.columns)\n\n# =========================================================\n# 3) DATASET\n# =========================================================\nclass ImgPathDataset(Dataset):\n    def __init__(self, item_ids, img_dir):\n        self.item_ids = [int(i) for i in item_ids]\n        self.img_dir = Path(img_dir)\n\n    def __len__(self):\n        return len(self.item_ids)\n\n    def __getitem__(self, idx):\n        iid = self.item_ids[idx]\n        return iid, str(self.img_dir / f\"{iid}.jpg\")\n\ndef _safe_open_rgb(path, size=(224,224)):\n    try:\n        return Image.open(path).convert(\"RGB\")\n    except Exception:\n        return Image.fromarray(np.zeros((size[0], size[1], 3), dtype=np.uint8))\n\ndef make_collate(processor: CLIPImageProcessor):\n    def collate(batch):\n        ids = [b[0] for b in batch]\n        paths = [b[1] for b in batch]\n        imgs = [_safe_open_rgb(p) for p in paths]\n        inputs = processor(images=imgs, return_tensors=\"pt\")\n        return torch.tensor(ids, dtype=torch.long), inputs[\"pixel_values\"]\n    return collate\n\n# =========================================================\n# 4) EXTRACT (memmap)\n# =========================================================\ndef extract_clip_features_memmap(\n    item_ids,\n    img_dir,\n    model_id=\"openai/clip-vit-base-patch32\",\n    out_memmap_path=\"/kaggle/working/clip_img_feats.f16.mmap\",\n    batch_size=256,\n    num_workers=4,\n    use_projected_512=True,\n    device=None\n):\n    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    processor = CLIPImageProcessor.from_pretrained(model_id)\n    model = CLIPModel.from_pretrained(model_id).to(device).eval()\n\n    ds = ImgPathDataset(item_ids, img_dir)\n    dl = DataLoader(\n        ds,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True,\n        persistent_workers=(num_workers > 0),\n        collate_fn=make_collate(processor),\n        prefetch_factor=2 if num_workers > 0 else None\n    )\n\n    feat_dim = model.config.projection_dim if use_projected_512 else model.vision_model.config.hidden_size\n\n    feats = np.memmap(out_memmap_path, mode=\"w+\", dtype=np.float16, shape=(len(ds), feat_dim))\n    ids_out = np.zeros((len(ds),), dtype=np.int32)\n\n    idx0 = 0\n    pbar = tqdm(dl, desc=f\"CLIP extract ({feat_dim}d)\")\n    with torch.inference_mode():\n        for ids, px in pbar:\n            bs = ids.shape[0]\n            px = px.to(device, non_blocking=True)\n\n            with torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=str(device).startswith(\"cuda\")):\n                if use_projected_512:\n                    out = model.get_image_features(pixel_values=px)  # [B,512]\n                else:\n                    out = model.vision_model(pixel_values=px).last_hidden_state[:, 0, :]  # [B,768]\n                out = F.normalize(out, dim=-1)\n\n            out = out.detach().cpu().numpy().astype(np.float16)\n            feats[idx0:idx0+bs] = out\n            ids_out[idx0:idx0+bs] = ids.numpy().astype(np.int32)\n            idx0 += bs\n\n    feats.flush()\n    del model, processor, ds, dl\n    gc.collect()\n    if str(device).startswith(\"cuda\"):\n        torch.cuda.empty_cache()\n\n    return out_memmap_path, ids_out, feat_dim\n\n# =========================================================\n# 5) RUN\n# =========================================================\nitem_ids_all = item_info[\"item_id\"].to_list()  # ✅ maintenant item_info existe\n\nmmap_path, clip_ids, clip_dim = extract_clip_features_memmap(\n    item_ids=item_ids_all,\n    img_dir=cfg.IMG_DIR,\n    model_id=cfg.CLIP_MODEL_ID,\n    out_memmap_path=f\"{cfg.WORK_DIR}/clip_img_feats.f16.mmap\",\n    batch_size=256,     # 128 si OOM\n    num_workers=4,\n    use_projected_512=True,\n    device=cfg.DEVICE\n)\n\nprint(\"✅ CLIP dim:\", clip_dim)\nprint(\"✅ saved memmap:\", mmap_path)\nprint(\"✅ ids:\", clip_ids.shape, \"example:\", clip_ids[:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T23:29:09.202200Z","iopub.execute_input":"2025-12-18T23:29:09.202542Z","iopub.status.idle":"2025-12-18T23:35:50.895050Z","shell.execute_reply.started":"2025-12-18T23:29:09.202514Z","shell.execute_reply":"2025-12-18T23:35:50.894251Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n✅ item_info: (91718, 3) ['item_id', 'item_tags', 'item_emb_d128']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e20b719eeed4f438ecb032bfe40b414"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a4b2dfdf1f54db4bad6f4fa09f50543"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c80c8a235fb49298549a06209bb97d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31c877847be340688fc95e640ac74fe8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"CLIP extract (512d):   0%|          | 0/359 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b51d78d4cd2e443b97a552a76b2a0f5f"}},"metadata":{}},{"name":"stdout","text":"✅ CLIP dim: 512\n✅ saved memmap: /kaggle/working/clip_img_feats.f16.mmap\n✅ ids: (91718,) example: [0 1 2 3 4]\n","output_type":"stream"}],"execution_count":14},{"id":"b38e3c91","cell_type":"markdown","source":"# 6) Student projector (CLIP → 128d) avec **Cosine + InfoNCE**\nOn aligne les items qui ont à la fois :\n- CLIP feature\n- teacher embedding\n\nPuis on entraîne un projecteur MLP.\n\n**Loss :**\n- `L_cos = 1 - cosine(student, teacher)`\n- `L_nce = cross_entropy(sim(student, teacher)/T)` (diagonal positives in-batch)\n\n> Cette distillation marche souvent mieux que MSE pour la recommandation.\n","metadata":{}},{"id":"c334f91d","cell_type":"code","source":"# =========================================================\n# 0) IMPORTS + FLAGS\n# =========================================================\nimport os, gc\nimport numpy as np\nimport polars as pl\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\ntorch.backends.cuda.matmul.allow_tf32 = True\ntorch.backends.cudnn.benchmark = True\n\nDEVICE = cfg.DEVICE\nSEED   = getattr(cfg, \"SEED\", 42)\n\ndef seed_everything(seed=42):\n    import random\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nseed_everything(SEED)\n\n# =========================================================\n# 1) LOAD TEACHER (128d) + item_ids\n# =========================================================\nitem_info = pl.read_parquet(f\"{cfg.WORK_DIR}/item_info.parquet\")  # ou cfg.ITEM_INFO\nitem_ids = item_info[\"item_id\"].to_list()\nn_items  = item_info.height\n\nteacher128 = np.vstack([np.array(v, dtype=np.float32) for v in item_info[\"item_emb_d128\"].to_list()])\nassert teacher128.shape == (n_items, 128)\n\n# Option : ignorer teacher quasi-zero (si coverage < 1.0)\nteacher_norm = np.linalg.norm(teacher128, axis=1)\nvalid_teacher = teacher_norm > 1e-8\n\nprint(\"✅ n_items:\", n_items)\nprint(\"✅ teacher128:\", teacher128.shape, \"valid_teacher:\", int(valid_teacher.sum()))\n\n# =========================================================\n# 2) LOAD CLIP MEMMAP (512d)\n# =========================================================\nclip_dim = 512\nclip_path = f\"{cfg.WORK_DIR}/clip_img_feats.f16.mmap\"\n\nclip_mem = np.memmap(clip_path, mode=\"r\", dtype=np.float16, shape=(n_items, clip_dim))\n# On ne cast PAS tout en float32 ici (sinon RAM). On cast par batch dans __getitem__.\n\nprint(\"✅ clip memmap ok:\", clip_path)\n\n# =========================================================\n# 3) BUILD TRAIN INDEXES (aligned pairs)\n# =========================================================\nitem_id_arr = np.array(item_ids, dtype=np.int64)\nvalid = (item_id_arr != 0) & valid_teacher  # padding row 0 out\n\ntrain_idx = np.where(valid)[0].astype(np.int32)\nprint(\"✅ aligned pairs:\", len(train_idx))\n\n# Option (rapide) : sous-échantillonner si tu veux aller plus vite\n# ex: garder 60k exemples\nMAX_PAIRS = getattr(cfg, \"PROJ_MAX_PAIRS\", 0)  # 0 => tout\nif MAX_PAIRS and len(train_idx) > MAX_PAIRS:\n    rng = np.random.default_rng(SEED)\n    train_idx = rng.choice(train_idx, size=MAX_PAIRS, replace=False).astype(np.int32)\n    print(\"✅ sampled pairs:\", len(train_idx))\n\n# =========================================================\n# 4) DATASET (memmap-safe)\n# =========================================================\nclass PairIndexDataset(Dataset):\n    def __init__(self, indices, clip_mem, teacher128):\n        self.indices = indices\n        self.clip_mem = clip_mem\n        self.teacher = teacher128\n\n    def __len__(self):\n        return len(self.indices)\n\n    def __getitem__(self, i):\n        idx = int(self.indices[i])\n        x = np.array(self.clip_mem[idx], dtype=np.float32)  # [512] cast local\n        y = self.teacher[idx].astype(np.float32)           # [128]\n        return torch.from_numpy(x), torch.from_numpy(y)\n\nds = PairIndexDataset(train_idx, clip_mem, teacher128)\n\ndl = DataLoader(\n    ds,\n    batch_size=cfg.PROJ_BATCH,\n    shuffle=True,\n    num_workers=0,          # ✅ le plus stable avec memmap (tu peux tenter 2 si OK)\n    pin_memory=True,\n    drop_last=True\n)\n\n# =========================================================\n# 5) PROJECTOR MLP\n# =========================================================\nclass Projector(nn.Module):\n    def __init__(self, in_dim, out_dim=128, hidden=256, dropout=0.1):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(in_dim, hidden),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden, out_dim),\n        )\n    def forward(self, x):\n        x = self.net(x)\n        x = F.normalize(x, dim=-1)\n        return x\n\nproj = Projector(\n    in_dim=clip_dim,\n    out_dim=cfg.EMB_DIM,\n    hidden=cfg.PROJ_HIDDEN,\n    dropout=cfg.PROJ_DROPOUT\n).to(DEVICE)\n\nopt = torch.optim.AdamW(proj.parameters(), lr=cfg.PROJ_LR, weight_decay=1e-4)\nscaler = torch.cuda.amp.GradScaler(enabled=str(DEVICE).startswith(\"cuda\"))\n\n# (option) petit scheduler simple\ntotal_steps = cfg.PROJ_EPOCHS * len(dl)\nsched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=max(1, total_steps))\n\n# =========================================================\n# 6) TRAIN (Cosine + InfoNCE symétrique)\n# =========================================================\nT = float(cfg.TEMPERATURE)\nalpha = float(cfg.ALPHA_COS)\nbeta  = float(cfg.BETA_NCE)\n\nfor ep in range(cfg.PROJ_EPOCHS):\n    proj.train()\n    pbar = tqdm(dl, desc=f\"Projector epoch {ep+1}/{cfg.PROJ_EPOCHS}\")\n    run_loss = 0.0\n\n    for step, (x, y) in enumerate(pbar):\n        x = x.to(DEVICE, non_blocking=True)\n        y = y.to(DEVICE, non_blocking=True)\n        y = F.normalize(y, dim=-1)\n\n        opt.zero_grad(set_to_none=True)\n\n        with torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=str(DEVICE).startswith(\"cuda\")):\n            z = proj(x)  # [B,128]\n\n            # cosine loss\n            cos = (z * y).sum(-1)              # [B]\n            loss_cos = (1.0 - cos).mean()\n\n            # InfoNCE in-batch (z vs y)\n            sim_zy = (z @ y.t()) / T           # [B,B]\n            labels = torch.arange(sim_zy.size(0), device=DEVICE)\n            loss_nce_1 = F.cross_entropy(sim_zy, labels)\n\n            # InfoNCE symétrique (y vs z) -> souvent un petit gain\n            sim_yz = (y @ z.t()) / T\n            loss_nce_2 = F.cross_entropy(sim_yz, labels)\n\n            loss_nce = 0.5 * (loss_nce_1 + loss_nce_2)\n\n            loss = alpha * loss_cos + beta * loss_nce\n\n        scaler.scale(loss).backward()\n        scaler.unscale_(opt)\n        nn.utils.clip_grad_norm_(proj.parameters(), 1.0)\n        scaler.step(opt)\n        scaler.update()\n        sched.step()\n\n        run_loss += float(loss.item())\n        pbar.set_postfix(\n            loss=run_loss/(step+1),\n            cos=float(cos.mean().item()),\n            nce=float(loss_nce.item()),\n            lr=float(opt.param_groups[0][\"lr\"])\n        )\n\nprint(\"✅ Projector trained.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T23:43:23.925722Z","iopub.execute_input":"2025-12-18T23:43:23.926518Z","iopub.status.idle":"2025-12-18T23:43:32.621764Z","shell.execute_reply.started":"2025-12-18T23:43:23.926482Z","shell.execute_reply":"2025-12-18T23:43:32.621052Z"}},"outputs":[{"name":"stdout","text":"✅ n_items: 91718\n✅ teacher128: (91718, 128) valid_teacher: 91717\n✅ clip memmap ok: /kaggle/working/clip_img_feats.f16.mmap\n✅ aligned pairs: 91717\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Projector epoch 1/3:   0%|          | 0/179 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"311d0de426ec40d0b17a814859d314ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Projector epoch 2/3:   0%|          | 0/179 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4bbcb5237784b7d9dfeeec6c06ac424"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Projector epoch 3/3:   0%|          | 0/179 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c2e768296b441c1b58df0ed781917e9"}},"metadata":{}},{"name":"stdout","text":"✅ Projector trained.\n","output_type":"stream"}],"execution_count":15},{"id":"79cd7d6f","cell_type":"markdown","source":"# 7) Construire `item_emb_d128` final (fusion teacher + student)\n- Si item a teacher : fusion (gate) **ou** moyenne\n- Sinon : student (cold-start)\n- `item_id=0` => vecteur **zéro**\n","metadata":{}},{"id":"cb517380","cell_type":"code","source":"import numpy as np\nimport polars as pl\nimport gc\nfrom tqdm.auto import tqdm\nimport torch\nimport torch.nn.functional as F\n\nDEVICE = cfg.DEVICE\nEMB_DIM = cfg.EMB_DIM\nclip_dim = 512\n\n# =========================\n# 1) Reload item_info + teacher128\n# =========================\nitem_info = pl.read_parquet(f\"{cfg.WORK_DIR}/item_info.parquet\")\nitem_ids = np.array(item_info[\"item_id\"].to_list(), dtype=np.int64)\nn_items = item_info.height\n\nteacher128 = np.vstack([np.array(v, dtype=np.float32) for v in item_info[\"item_emb_d128\"].to_list()])\nteacher128[0] = 0.0  # padding\nteacher128 = teacher128.astype(np.float32)\n\n# normalize teacher\nt_norm = np.linalg.norm(teacher128, axis=1, keepdims=True) + 1e-12\nteacherN = teacher128 / t_norm\n\nprint(\"✅ n_items:\", n_items, \"teacher128:\", teacher128.shape)\n\n# =========================\n# 2) Load CLIP memmap (float16)\n# =========================\nclip_mem = np.memmap(\n    f\"{cfg.WORK_DIR}/clip_img_feats.f16.mmap\",\n    mode=\"r\", dtype=np.float16, shape=(n_items, clip_dim)\n)\n\n# =========================\n# 3) Fonction gating (cos-based) en batch\n# g = clamp((cos+1)/2)  -> stable et simple\n# final = g*teacher + (1-g)*student   (ou l'inverse si tu veux)\n# =========================\n@torch.no_grad()\ndef build_final_embeddings_from_memmap(\n    proj,\n    clip_mem,\n    teacherN,\n    batch_size=4096\n):\n    proj.eval()\n\n    final = np.zeros((n_items, EMB_DIM), dtype=np.float32)\n\n    # item 0 = zeros\n    final[0] = 0.0\n\n    pbar = tqdm(range(1, n_items, batch_size), desc=\"Infer+Fuse (memmap)\")\n    for i0 in pbar:\n        i1 = min(n_items, i0 + batch_size)\n\n        # ---- CLIP batch -> torch\n        x = np.array(clip_mem[i0:i1], dtype=np.float32)  # cast local\n        x = torch.from_numpy(x).to(DEVICE, non_blocking=True)\n\n        # ---- student\n        with torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=str(DEVICE).startswith(\"cuda\")):\n            s = proj(x)  # [B,128] déjà normalized\n\n        # ---- teacher normalized batch\n        t = torch.from_numpy(teacherN[i0:i1]).to(DEVICE, non_blocking=True)  # [B,128]\n\n        # ---- cosine + gate\n        cos = (t * s).sum(-1)                         # [-1,1]\n        g = torch.clamp((cos + 1.0) * 0.5, 0.0, 1.0)  # [0,1]\n\n        # ---- fusion\n        # (tu peux inverser si tu veux favoriser student)\n        v = g.unsqueeze(-1) * t + (1.0 - g).unsqueeze(-1) * s\n        v = F.normalize(v, dim=-1)\n\n        final[i0:i1] = v.detach().cpu().numpy().astype(np.float32)\n\n    return final\n\nfinal128 = build_final_embeddings_from_memmap(\n    proj=proj,\n    clip_mem=clip_mem,\n    teacherN=teacherN,\n    batch_size=4096  # 2048/4096/8192 selon GPU\n)\n\nprint(\"✅ final128:\", final128.shape, \"norm[1]:\", np.linalg.norm(final128[1]))\n\n# =========================\n# 4) Save item_info.parquet final\n# =========================\nout_path = f\"{cfg.WORK_DIR}/item_info.parquet\"\nitem_info_new = item_info.with_columns(\n    pl.Series(\"item_emb_d128\", final128.tolist())\n)\nitem_info_new.write_parquet(out_path)\n\nprint(\"✅ Saved final item_info:\", out_path)\n\n# cleanup\ndel item_info_new, item_info, teacher128, teacherN, final128\ngc.collect()\nif str(DEVICE).startswith(\"cuda\"):\n    torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T23:47:14.334046Z","iopub.execute_input":"2025-12-18T23:47:14.334636Z","iopub.status.idle":"2025-12-18T23:47:39.815208Z","shell.execute_reply.started":"2025-12-18T23:47:14.334608Z","shell.execute_reply":"2025-12-18T23:47:39.814254Z"}},"outputs":[{"name":"stdout","text":"✅ n_items: 91718 teacher128: (91718, 128)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Infer+Fuse (memmap):   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88ea6be4cb794b32ae34cc59a61d058e"}},"metadata":{}},{"name":"stdout","text":"✅ final128: (91718, 128) norm[1]: 0.99999994\n✅ Saved final item_info: /kaggle/working/item_info.parquet\n","output_type":"stream"}],"execution_count":16},{"id":"1bbc504d","cell_type":"markdown","source":"# 8) Écrire `item_info_updated.parquet` (IMPORTANT)\n- On garde toutes les colonnes\n- On remplace **uniquement** `item_emb` (ou on crée `item_emb`)\n- On garde la première ligne padding (item_id=0)\n","metadata":{}},{"id":"e5e72c10","cell_type":"code","source":"import polars as pl\nimport numpy as np\n\ndf = pl.read_parquet(\"/kaggle/working/item_info.parquet\")\n\nfinal128 = np.vstack([np.array(v, dtype=np.float32) for v in df[\"item_emb_d128\"].to_list()])\nprint(\"final128:\", final128.shape)\n\n# sécurité padding\nif int(df[\"item_id\"][0]) == 0:\n    final128[0] = 0.0\n\ndf_upd = df.with_columns(pl.Series(\"item_emb\", final128.tolist()))\n\nout_path = \"/kaggle/working/item_info_updated.parquet\"\ndf_upd.write_parquet(out_path)\n\nprint(\"✅ Saved:\", out_path)\nprint(df_upd.select([\"item_id\",\"item_emb\"]).head(3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T23:52:02.698131Z","iopub.execute_input":"2025-12-18T23:52:02.698523Z","iopub.status.idle":"2025-12-18T23:52:07.323040Z","shell.execute_reply.started":"2025-12-18T23:52:02.698496Z","shell.execute_reply":"2025-12-18T23:52:07.322291Z"}},"outputs":[{"name":"stdout","text":"final128: (91718, 128)\n✅ Saved: /kaggle/working/item_info_updated.parquet\nshape: (3, 2)\n┌─────────┬─────────────────────────────────┐\n│ item_id ┆ item_emb                        │\n│ ---     ┆ ---                             │\n│ i64     ┆ list[f64]                       │\n╞═════════╪═════════════════════════════════╡\n│ 0       ┆ [0.0, 0.0, … 0.0]               │\n│ 1       ┆ [-0.159443, 0.273246, … 0.0841… │\n│ 2       ┆ [-0.221092, 0.021761, … 0.0078… │\n└─────────┴─────────────────────────────────┘\n","output_type":"stream"}],"execution_count":18},{"id":"5dce43fe","cell_type":"markdown","source":"# 9) CTR training & inference (FuxiCTR baseline + modèles plus forts)\nDeux modes :\n- **Task1 compliant** : DIN baseline + hyperparams limités\n- **Task1&2** : tu peux tester des modèles plus forts : **DCNv2**, **AutoInt**, etc.\n\nOn clone le repo officiel et on prépare les fichiers.\n","metadata":{}},{"id":"a568944e-d97b-41f1-9a31-477a3770fd38","cell_type":"code","source":"# =========================================================\n# 9.0) CLONE PROPRE + INSTALL + PREP DATA (ROBUST)\n# =========================================================\nfrom pathlib import Path\nimport shutil, os, gc\nimport polars as pl\nimport numpy as np\n\nWORK_DIR = Path(\"/kaggle/working\")\n\n# 1) Ton dossier data déjà prêt (d'après ton screenshot)\nDATA_READY_DIR = WORK_DIR / \"WWW2025_MMCTR_Challenge\" / \"data\" / cfg.DATASET_ID\nassert DATA_READY_DIR.exists(), f\"Data dir introuvable: {DATA_READY_DIR}\"\n\nprint(\"✅ DATA_READY_DIR:\", DATA_READY_DIR)\nprint(\"   files:\", [p.name for p in DATA_READY_DIR.iterdir()])\n\n# 2) Clone dans un autre dossier (pour ne pas écraser tes fichiers)\nREPO_CLONE_DIR = WORK_DIR / \"WWW2025_MMCTR_Challenge_repo\"\n\nif REPO_CLONE_DIR.exists():\n    print(\"ℹ️ Repo clone dir existe déjà:\", REPO_CLONE_DIR)\nelse:\n    !git clone -q --depth 1 https://github.com/reczoo/WWW2025_MMCTR_Challenge.git {str(REPO_CLONE_DIR)}\n    print(\"✅ Repo cloné dans:\", REPO_CLONE_DIR)\n\n# 3) Installer dépendances (silencieux)\nreq = REPO_CLONE_DIR / \"requirements.txt\"\nif req.exists():\n    !pip -q install -r {str(req)}\nelse:\n    print(\"⚠️ requirements.txt introuvable (pas bloquant).\")\n\nprint(\"✅ Contenu repo (top-level):\", [p.name for p in REPO_CLONE_DIR.iterdir()][:30])\n\n# 4) Préparer data dir attendu PAR LE REPO cloné\nREPO_DATA_DIR = REPO_CLONE_DIR / \"data\" / cfg.DATASET_ID\nREPO_DATA_DIR.mkdir(parents=True, exist_ok=True)\n\n# On copie (ou remplace) le dossier dataset dans le repo cloné\n# => évite les erreurs de chemin lors du training\nfor f in [\"train.parquet\", \"valid.parquet\", \"test.parquet\", \"item_seq.parquet\", \"item_info.parquet\"]:\n    src = DATA_READY_DIR / f\n    assert src.exists(), f\"Fichier manquant dans DATA_READY_DIR: {src}\"\n    shutil.copy(src, REPO_DATA_DIR / f)\n\nprint(\"✅ Data copiée dans repo cloné:\", REPO_DATA_DIR)\nprint(\"   files:\", [p.name for p in REPO_DATA_DIR.iterdir()])\n\n# 5) Sanity check item_info format + colonne item_emb_d128\nii = pl.read_parquet(REPO_DATA_DIR / \"item_info.parquet\")\nprint(\"✅ item_info columns:\", ii.columns)\nassert \"item_emb_d128\" in ii.columns, \"item_emb_d128 manquant !\"\n\n# Si jamais item_emb_d128 est list au lieu de array, on peut forcer array[Float64,128]\n# (Optionnel mais recommandé)\ntry:\n    # Si c'est list, on convertit vers Array fixe 128\n    if \"list\" in str(ii.schema[\"item_emb_d128\"]).lower():\n        arr = np.array(ii[\"item_emb_d128\"].to_list(), dtype=np.float64)\n        assert arr.shape[1] == 128\n        ii = ii.with_columns(\n            pl.Series(\"item_emb_d128\", arr.tolist()).cast(pl.Array(pl.Float64, 128))\n        )\n        ii.write_parquet(REPO_DATA_DIR / \"item_info.parquet\")\n        print(\"✅ item_emb_d128 casté en Array(Float64,128)\")\nexcept Exception as e:\n    print(\"ℹ️ Cast optionnel ignoré:\", e)\n\nprint(\"✅ DONE 9.0\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T00:19:36.241734Z","iopub.execute_input":"2025-12-19T00:19:36.242037Z","iopub.status.idle":"2025-12-19T00:19:49.664615Z","shell.execute_reply.started":"2025-12-19T00:19:36.242016Z","shell.execute_reply":"2025-12-19T00:19:49.663588Z"}},"outputs":[{"name":"stdout","text":"✅ DATA_READY_DIR: /kaggle/working/WWW2025_MMCTR_Challenge/data/MicroLens_1M_x1\n   files: ['valid.parquet', 'train.parquet', 'item_seq.parquet', 'item_info.parquet', 'test.parquet']\n✅ Repo cloné dans: /kaggle/working/WWW2025_MMCTR_Challenge_repo\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.1/88.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf-polars-cu12 25.6.0 requires polars<1.29,>=1.25, but you have polars 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m✅ Contenu repo (top-level): ['requirements.txt', 'src', 'data', 'run_param_tuner.py', 'README.md', 'prediction.py', 'img', 'config', 'fuxictr_version.py', '.git', '.gitignore', 'LICENSE', 'run_expid.py']\n✅ Data copiée dans repo cloné: /kaggle/working/WWW2025_MMCTR_Challenge_repo/data/MicroLens_1M_x1\n   files: ['valid.parquet', 'train.parquet', 'item_seq.parquet', 'item_info.parquet', 'test.parquet']\n✅ item_info columns: ['item_id', 'item_tags', 'item_emb', 'item_emb_d128']\n✅ item_emb_d128 casté en Array(Float64,128)\n✅ DONE 9.0\n","output_type":"stream"}],"execution_count":25},{"id":"454f7f08-da2f-4452-8eda-2e5d32065d75","cell_type":"markdown","source":"#### convertir proprement en float32","metadata":{}},{"id":"9a0fe8f3-acac-4494-8076-3c14e4092f36","cell_type":"code","source":"import polars as pl\nimport numpy as np\nfrom pathlib import Path\n\nDATA_DIR = Path(\"/kaggle/working/WWW2025_MMCTR_Challenge/data/MicroLens_1M_x1\")\npath_in  = DATA_DIR / \"item_info.parquet\"\n\nii = pl.read_parquet(path_in)\n\n# conversion list[f64] -> list[f32]\nemb32 = [np.asarray(v, dtype=np.float32).tolist() for v in ii[\"item_emb_d128\"].to_list()]\nii = ii.drop(\"item_emb_d128\").with_columns(pl.Series(\"item_emb_d128\", emb32))\n\n# réécriture\nii.write_parquet(path_in)\n\nprint(\"✅ Re-saved in float32:\", path_in)\nprint(ii.select([\"item_id\", \"item_emb_d128\"]).head(3))\nprint(\"Type:\", ii.schema[\"item_emb_d128\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T00:05:25.421976Z","iopub.execute_input":"2025-12-19T00:05:25.422413Z","iopub.status.idle":"2025-12-19T00:05:30.374089Z","shell.execute_reply.started":"2025-12-19T00:05:25.422380Z","shell.execute_reply":"2025-12-19T00:05:30.373312Z"}},"outputs":[{"name":"stdout","text":"✅ Re-saved in float32: /kaggle/working/WWW2025_MMCTR_Challenge/data/MicroLens_1M_x1/item_info.parquet\nshape: (3, 2)\n┌─────────┬─────────────────────────────────┐\n│ item_id ┆ item_emb_d128                   │\n│ ---     ┆ ---                             │\n│ i64     ┆ list[f64]                       │\n╞═════════╪═════════════════════════════════╡\n│ 0       ┆ [0.0, 0.0, … 0.0]               │\n│ 1       ┆ [-0.159443, 0.273246, … 0.0841… │\n│ 2       ┆ [-0.221092, 0.021761, … 0.0078… │\n└─────────┴─────────────────────────────────┘\nType: List(Float64)\n","output_type":"stream"}],"execution_count":22},{"id":"9f7197f7","cell_type":"markdown","source":"## 9.1 Générer un YAML config (DIN / DCNv2 / AutoInt)\n- Pour **Task1** : reste sur **DIN** et modifie seulement :\n  - `learning_rate`, `batch_size`, `net_dropout`, `embedding_regularizer`, `net_regularizer`\n- Pour **Task1&2** : tu peux changer le modèle + plus d’hyperparams.\n\n> ⚠️ Le fichier YAML de base est dans :  \n`config/MMCTR/{DATASET_ID}/...yaml`\n","metadata":{}},{"id":"7076175f","cell_type":"code","source":"# =========================================================\n# 9.1) AUTO-FIND YAML TEMPLATE + GENERATE CONFIGS (ROBUST)\n# =========================================================\nfrom pathlib import Path\nimport yaml, copy\n\nREPO_DIR = Path(\"/kaggle/working/WWW2025_MMCTR_Challenge_repo\")\nassert REPO_DIR.exists(), f\"Repo introuvable: {REPO_DIR}\"\nprint(\"✅ REPO_DIR:\", REPO_DIR)\n\nds_id = cfg.DATASET_ID  # \"MicroLens_1M_x1\"\ndata_root = str(REPO_DIR / \"data\")\n\n# ---------------------------------------------------------\n# 1) Trouver tous les YAML dans le repo\n# ---------------------------------------------------------\nyaml_files = sorted(list(REPO_DIR.rglob(\"*.yaml\")) + list(REPO_DIR.rglob(\"*.yml\")))\nprint(\"✅ Nb YAML trouvés:\", len(yaml_files))\nif len(yaml_files) == 0:\n    raise FileNotFoundError(\"Aucun YAML trouvé dans le repo cloné. Vérifie /config dans le repo.\")\n\n# ---------------------------------------------------------\n# 2) Priorité: YAML liés à MMCTR + dataset\n# ---------------------------------------------------------\nds_candidates = [p for p in yaml_files if ds_id.lower() in str(p).lower()]\nif len(ds_candidates) == 0:\n    ds_candidates = [p for p in yaml_files if \"mmctr\" in str(p).lower()]\nif len(ds_candidates) == 0:\n    ds_candidates = yaml_files[:]  # fallback\n\nprint(\"✅ YAML candidates:\", len(ds_candidates))\n\n# ---------------------------------------------------------\n# 3) Choisir un template DIN si possible\n# ---------------------------------------------------------\ndef is_din_yaml(p: Path):\n    return \"din\" in p.name.lower()\n\ndin_candidates = [p for p in ds_candidates if is_din_yaml(p)]\ntemplate_path = din_candidates[0] if len(din_candidates) > 0 else ds_candidates[0]\nprint(\"✅ Template choisi:\", template_path)\n\n# ---------------------------------------------------------\n# 4) Load/Save YAML\n# ---------------------------------------------------------\ndef load_yaml(path: Path):\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        return yaml.safe_load(f)\n\ndef save_yaml(obj, path: Path):\n    path.parent.mkdir(parents=True, exist_ok=True)\n    with open(path, \"w\", encoding=\"utf-8\") as f:\n        yaml.safe_dump(obj, f, sort_keys=False, allow_unicode=True)\n\nbase_yaml = load_yaml(template_path)\n\n# ---------------------------------------------------------\n# 5) Update keys recursively (robuste)\n# ---------------------------------------------------------\ndef set_keys_recursive(obj, mapping):\n    \"\"\"\n    mapping: dict key->value ; si la clé existe n'importe où dans la structure, on la remplace.\n    \"\"\"\n    if isinstance(obj, dict):\n        for k in list(obj.keys()):\n            if k in mapping:\n                obj[k] = mapping[k]\n            else:\n                set_keys_recursive(obj[k], mapping)\n    elif isinstance(obj, list):\n        for it in obj:\n            set_keys_recursive(it, mapping)\n\ndef ensure_tuner_params(y):\n    if \"tuner_params\" not in y or y[\"tuner_params\"] is None or not isinstance(y[\"tuner_params\"], dict):\n        y[\"tuner_params\"] = {}\n    return y\n\n# ---------------------------------------------------------\n# 6) Générer configs (DIN Task1 / DCNv2 Task1&2)\n# ---------------------------------------------------------\ndef make_config(model_name=\"DIN\", task1_compliant=True):\n    y = copy.deepcopy(base_yaml)\n\n    # model name (si la clé existe)\n    if isinstance(y, dict):\n        y[\"model\"] = model_name\n\n    # mettre dataset_id + data_root où ça existe\n    set_keys_recursive(y, {\n        \"dataset_id\": ds_id,\n        \"data_root\": data_root,\n        \"data_dir\": data_root,\n        \"data_path\": data_root\n    })\n\n    y = ensure_tuner_params(y)\n\n    if task1_compliant:\n        # ✅ Task1: uniquement hyperparams autorisés\n        y[\"tuner_params\"] = {\n            \"learning_rate\": [1e-3, 5e-4],\n            \"batch_size\": [2048, 4096],\n            \"net_dropout\": [0.0, 0.1, 0.2],\n            \"embedding_regularizer\": [0.0, 1e-7, 1e-6],\n            \"net_regularizer\": [0.0, 1e-7, 1e-6],\n        }\n    else:\n        tp = y[\"tuner_params\"]\n        tp[\"learning_rate\"] = [1e-3, 5e-4, 2e-4]\n        tp[\"batch_size\"] = [1024, 2048, 4096]\n        tp[\"net_dropout\"] = [0.0, 0.1, 0.2, 0.3]\n        tp[\"embedding_regularizer\"] = [0.0, 1e-7, 1e-6, 1e-5]\n        tp[\"net_regularizer\"] = [0.0, 1e-7, 1e-6, 1e-5]\n\n        if model_name.lower() in [\"dcnv2\", \"autoint\"]:\n            tp[\"dnn_hidden_units\"] = [\"[512,256,128]\", \"[1024,512,256]\"]\n\n    return y\n\nOUT_CFG_DIR = REPO_DIR / \"config\" / \"CUSTOM\"\ntask1_yaml_path  = OUT_CFG_DIR / f\"DIN_{ds_id}_task1_aucboost.yaml\"\ntask12_yaml_path = OUT_CFG_DIR / f\"DCNv2_{ds_id}_task12_aucboost.yaml\"\n\nsave_yaml(make_config(\"DIN\", task1_compliant=True), task1_yaml_path)\nsave_yaml(make_config(\"DCNv2\", task1_compliant=False), task12_yaml_path)\n\nprint(\"✅ Saved configs:\")\nprint(\" -\", task1_yaml_path)\nprint(\" -\", task12_yaml_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T00:26:19.488975Z","iopub.execute_input":"2025-12-19T00:26:19.489819Z","iopub.status.idle":"2025-12-19T00:26:19.524366Z","shell.execute_reply.started":"2025-12-19T00:26:19.489784Z","shell.execute_reply":"2025-12-19T00:26:19.523501Z"}},"outputs":[{"name":"stdout","text":"✅ REPO_DIR: /kaggle/working/WWW2025_MMCTR_Challenge_repo\n✅ Nb YAML trouvés: 2\n✅ YAML candidates: 2\n✅ Template choisi: /kaggle/working/WWW2025_MMCTR_Challenge_repo/config/DIN_microlens_mmctr_tuner_config_01.yaml\n✅ Saved configs:\n - /kaggle/working/WWW2025_MMCTR_Challenge_repo/config/CUSTOM/DIN_MicroLens_1M_x1_task1_aucboost.yaml\n - /kaggle/working/WWW2025_MMCTR_Challenge_repo/config/CUSTOM/DCNv2_MicroLens_1M_x1_task12_aucboost.yaml\n","output_type":"stream"}],"execution_count":26},{"id":"f0d436f4","cell_type":"markdown","source":"## 9.2 Training (param tuner)\nExécute **un** des deux :\n- Task1 : `DIN_task1_aucboost.yaml`\n- Task1&2 : `DCNv2_task12_aucboost.yaml` (ou change model_name)\n\n> Kaggle GPU recommandé.\n","metadata":{}},{"id":"d6d45897","cell_type":"code","source":"# =========================================================\n# 9.x) FIX NumPy2 + PREP + RUN PARAM TUNER (FULL)\n# =========================================================\nimport os, sys, gc, re, warnings, shutil\nfrom pathlib import Path\n\nwarnings.filterwarnings(\"ignore\")\n\n# -------------------------\n# 0) Paths (adapte si besoin)\n# -------------------------\nREPO_DIR = Path(\"/kaggle/working/WWW2025_MMCTR_Challenge_repo\")  # ton repo cloné\nDATASET_ID = \"MicroLens_1M_x1\"                                  # cfg.DATASET_ID\nDATA_DIR = REPO_DIR / \"data\" / DATASET_ID                       # data déjà copiée\nCFG_PATH = REPO_DIR / \"config\" / \"CUSTOM\" / f\"DCNv2_{DATASET_ID}_task12_aucboost.yaml\"  # ton yaml custom\nGPU_ID = 0\n\nprint(\"✅ REPO_DIR:\", REPO_DIR)\nprint(\"✅ DATA_DIR:\", DATA_DIR)\nprint(\"✅ CFG_PATH:\", CFG_PATH)\n\nassert REPO_DIR.exists(), f\"Repo introuvable: {REPO_DIR}\"\nassert DATA_DIR.exists(), f\"Data dir introuvable: {DATA_DIR}\"\nassert CFG_PATH.exists(), f\"YAML config introuvable: {CFG_PATH}\"\n\nprint(\"✅ files data:\", sorted([p.name for p in DATA_DIR.iterdir() if p.is_file()]))\n\n# =========================================================\n# 1) FIX CRASH NumPy2: patch np.Inf -> np.inf dans FuxiCTR\n# =========================================================\ndef patch_np_inf_in_fuxictr():\n    \"\"\"\n    Patch fuxictr rank_model.py: np.Inf -> np.inf (NumPy 2.0 compat)\n    \"\"\"\n    import fuxictr\n    base = Path(fuxictr.__file__).parent\n    target = base / \"pytorch\" / \"models\" / \"rank_model.py\"\n    if not target.exists():\n        print(\"⚠️ rank_model.py introuvable, on cherche dans site-packages...\")\n        # fallback search\n        import site\n        found = []\n        for sp in site.getsitepackages():\n            cand = Path(sp) / \"fuxictr\" / \"pytorch\" / \"models\" / \"rank_model.py\"\n            if cand.exists():\n                found.append(cand)\n        if not found:\n            raise FileNotFoundError(\"Impossible de trouver fuxictr/pytorch/models/rank_model.py\")\n        target = found[0]\n\n    txt = target.read_text(encoding=\"utf-8\")\n    if \"np.Inf\" not in txt and \"-np.Inf\" not in txt:\n        print(\"✅ Patch déjà OK (np.Inf absent):\", target)\n        return\n\n    txt2 = txt.replace(\"np.Inf\", \"np.inf\").replace(\"-np.Inf\", \"-np.inf\")\n    target.write_text(txt2, encoding=\"utf-8\")\n    print(\"✅ Patch appliqué:\", target)\n    print(\"✅ Vérif np.Inf encore présent ?\", (\"np.Inf\" in target.read_text(encoding=\"utf-8\")))\n\n# Appliquer patch\npatch_np_inf_in_fuxictr()\n\n# =========================================================\n# 2) (Optionnel) Vérification rapide versions\n# =========================================================\nimport numpy as np\nprint(\"✅ numpy:\", np.__version__)\n\n# =========================================================\n# 3) Lancer le training (param tuner)\n# =========================================================\nos.chdir(str(REPO_DIR))\nprint(\"📂 Current dir:\", os.getcwd())\n\n# Important: sur Kaggle parfois python pointe vers /usr/bin/python\n# On utilise sys.executable pour être sûr.\ncmd = f'\"{sys.executable}\" run_param_tuner.py --config \"{CFG_PATH}\" --gpu {GPU_ID}'\nprint(\"▶️ CMD:\", cmd)\n\n# Exécution\nret = os.system(cmd)\nprint(\"✅ finished with code:\", ret)\n\n# =========================================================\n# 4) (Optionnel) Trouver le meilleur checkpoint produit\n# =========================================================\nckpt_dir = REPO_DIR / \"checkpoints\"\nif ckpt_dir.exists():\n    # Affiche quelques dossiers / fichiers récents\n    all_ckpt = sorted(ckpt_dir.rglob(\"*\"), key=lambda p: p.stat().st_mtime, reverse=True)[:20]\n    print(\"\\n📦 Derniers éléments checkpoints:\")\n    for p in all_ckpt:\n        print(\" -\", p.relative_to(REPO_DIR))\nelse:\n    print(\"⚠️ Pas de dossier checkpoints trouvé.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T00:38:39.113703Z","iopub.execute_input":"2025-12-19T00:38:39.114090Z","iopub.status.idle":"2025-12-19T06:39:35.434639Z","shell.execute_reply.started":"2025-12-19T00:38:39.114056Z","shell.execute_reply":"2025-12-19T06:39:35.433464Z"}},"outputs":[{"name":"stdout","text":"✅ REPO_DIR: /kaggle/working/WWW2025_MMCTR_Challenge_repo\n✅ DATA_DIR: /kaggle/working/WWW2025_MMCTR_Challenge_repo/data/MicroLens_1M_x1\n✅ CFG_PATH: /kaggle/working/WWW2025_MMCTR_Challenge_repo/config/CUSTOM/DCNv2_MicroLens_1M_x1_task12_aucboost.yaml\n✅ files data: ['feature_map.json', 'feature_processor.pkl', 'feature_vocab.json', 'item_info.parquet', 'item_seq.parquet', 'test.parquet', 'train.parquet', 'valid.parquet']\n✅ Patch appliqué: /usr/local/lib/python3.12/dist-packages/fuxictr/pytorch/models/rank_model.py\n✅ Vérif np.Inf encore présent ? False\n✅ numpy: 2.0.2\n📂 Current dir: /kaggle/working/WWW2025_MMCTR_Challenge_repo\n▶️ CMD: \"/usr/bin/python3\" run_param_tuner.py --config \"/kaggle/working/WWW2025_MMCTR_Challenge_repo/config/CUSTOM/DCNv2_MicroLens_1M_x1_task12_aucboost.yaml\" --gpu 0\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 00:38:42,703 P574 INFO FuxiCTR version: 2.3.7\n2025-12-19 00:38:42,704 P574 INFO Params: {\n    \"accumulation_steps\": \"1\",\n    \"attention_dropout\": \"0.1\",\n    \"attention_hidden_activations\": \"ReLU\",\n    \"attention_hidden_units\": \"[512, 256]\",\n    \"attention_output_activation\": \"None\",\n    \"batch_norm\": \"True\",\n    \"batch_size\": \"8192\",\n    \"data_format\": \"parquet\",\n    \"data_root\": \"/kaggle/working/WWW2025_MMCTR_Challenge_repo/data\",\n    \"dataset_id\": \"MicroLens_1M_x1\",\n    \"debug_mode\": \"False\",\n    \"din_use_softmax\": \"False\",\n    \"dnn_activations\": \"ReLU\",\n    \"dnn_hidden_units\": \"[1024, 512, 256]\",\n    \"early_stop_patience\": \"3\",\n    \"embedding_dim\": \"64\",\n    \"embedding_regularizer\": \"1e-06\",\n    \"epochs\": \"100\",\n    \"eval_steps\": \"None\",\n    \"feature_cols\": \"[{'active': True, 'dtype': 'int', 'name': 'user_id', 'type': 'meta'}, {'active': True, 'dtype': 'int', 'name': 'item_seq', 'type': 'meta'}, {'active': True, 'dtype': 'int', 'name': 'likes_level', 'type': 'categorical', 'vocab_size': 11}, {'active': True, 'dtype': 'int', 'name': 'views_level', 'type': 'categorical', 'vocab_size': 11}, {'active': True, 'dtype': 'int', 'name': 'item_id', 'source': 'item', 'type': 'categorical', 'vocab_size': 91718}, {'active': True, 'dtype': 'int', 'max_len': 5, 'name': 'item_tags', 'source': 'item', 'type': 'sequence', 'vocab_size': 11740}, {'active': True, 'dtype': 'float', 'embedding_dim': 128, 'name': 'item_emb_d128', 'source': 'item', 'type': 'embedding'}]\",\n    \"feature_config\": \"None\",\n    \"feature_specs\": \"None\",\n    \"gpu\": \"0\",\n    \"group_id\": \"user_id\",\n    \"item_info\": \"./data/MicroLens_1M_x1/item_info.parquet\",\n    \"label_col\": \"{'dtype': 'float', 'name': 'label'}\",\n    \"learning_rate\": \"0.001\",\n    \"loss\": \"binary_crossentropy\",\n    \"max_len\": \"64\",\n    \"metrics\": \"['AUC', 'logloss']\",\n    \"model\": \"DIN\",\n    \"model_id\": \"DIN_MicroLens_1M_x1_001_9377cbcb\",\n    \"model_root\": \"./checkpoints/\",\n    \"monitor\": \"AUC\",\n    \"monitor_mode\": \"max\",\n    \"net_dropout\": \"0.1\",\n    \"net_regularizer\": \"0\",\n    \"num_workers\": \"3\",\n    \"optimizer\": \"adam\",\n    \"pickle_feature_encoder\": \"True\",\n    \"rebuild_dataset\": \"False\",\n    \"save_best_only\": \"True\",\n    \"seed\": \"20242025\",\n    \"shuffle\": \"True\",\n    \"task\": \"binary_classification\",\n    \"test_data\": \"./data/MicroLens_1M_x1/test.parquet\",\n    \"train_data\": \"./data/MicroLens_1M_x1/train.parquet\",\n    \"use_features\": \"None\",\n    \"valid_data\": \"./data/MicroLens_1M_x1/valid.parquet\",\n    \"verbose\": \"1\"\n}\n2025-12-19 00:38:42,705 P574 INFO Set up feature processor...\n2025-12-19 00:38:42,705 P574 INFO Fit feature processor...\n2025-12-19 00:38:42,705 P574 INFO Processing column: {'active': True, 'dtype': 'int', 'name': 'user_id', 'type': 'meta'}\n2025-12-19 00:38:42,705 P574 INFO Processing column: {'active': True, 'dtype': 'int', 'name': 'item_seq', 'type': 'meta'}\n2025-12-19 00:38:42,705 P574 INFO Processing column: {'active': True, 'dtype': 'int', 'name': 'likes_level', 'type': 'categorical', 'vocab_size': 11}\n2025-12-19 00:38:42,706 P574 INFO Processing column: {'active': True, 'dtype': 'int', 'name': 'views_level', 'type': 'categorical', 'vocab_size': 11}\n2025-12-19 00:38:42,706 P574 INFO Processing column: {'active': True, 'dtype': 'int', 'name': 'item_id', 'source': 'item', 'type': 'categorical', 'vocab_size': 91718}\n2025-12-19 00:38:42,735 P574 INFO Processing column: {'active': True, 'dtype': 'int', 'max_len': 5, 'name': 'item_tags', 'source': 'item', 'type': 'sequence', 'vocab_size': 11740}\n2025-12-19 00:38:42,738 P574 INFO Processing column: {'active': True, 'dtype': 'float', 'embedding_dim': 128, 'name': 'item_emb_d128', 'source': 'item', 'type': 'embedding'}\n2025-12-19 00:38:42,738 P574 INFO Set column index...\n2025-12-19 00:38:42,738 P574 INFO Save feature_map to json: /kaggle/working/WWW2025_MMCTR_Challenge_repo/data/MicroLens_1M_x1/feature_map.json\n2025-12-19 00:38:42,738 P574 INFO Pickle feature_encode: /kaggle/working/WWW2025_MMCTR_Challenge_repo/data/MicroLens_1M_x1/feature_processor.pkl\n2025-12-19 00:38:42,745 P574 INFO Save feature_vocab to json: /kaggle/working/WWW2025_MMCTR_Challenge_repo/data/MicroLens_1M_x1/feature_vocab.json\n2025-12-19 00:38:42,879 P574 INFO Set feature processor done.\n2025-12-19 00:38:42,879 P574 INFO Load feature_map from json: /kaggle/working/WWW2025_MMCTR_Challenge_repo/data/MicroLens_1M_x1/feature_map.json\n2025-12-19 00:38:42,879 P574 INFO Set column index...\n2025-12-19 00:38:42,879 P574 INFO Feature specs: {\n    \"item_emb_d128\": \"{'source': 'item', 'type': 'embedding', 'embedding_dim': 128}\",\n    \"item_id\": \"{'source': 'item', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 91718}\",\n    \"item_seq\": \"{'type': 'meta'}\",\n    \"item_tags\": \"{'source': 'item', 'type': 'sequence', 'feature_encoder': 'layers.MaskedAveragePooling()', 'padding_idx': 0, 'max_len': 5, 'vocab_size': 11740}\",\n    \"likes_level\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 11}\",\n    \"user_id\": \"{'type': 'meta'}\",\n    \"views_level\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 11}\"\n}\n2025-12-19 00:38:44,184 P574 INFO Total number of parameters: 8611842.\n2025-12-19 00:38:44,184 P574 INFO Loading datasets...\n2025-12-19 00:38:55,377 P574 INFO Train samples: total/3600000, blocks/1\n2025-12-19 00:38:56,147 P574 INFO Validation samples: total/10000, blocks/1\n2025-12-19 00:38:56,147 P574 INFO Loading train and validation data done.\n2025-12-19 00:38:56,148 P574 INFO Start training: 440 batches/epoch\n2025-12-19 00:38:56,148 P574 INFO ************ Epoch=1 start ************\n","output_type":"stream"},{"name":"stdout","text":"100%|█████████▉| 439/440 [08:10<00:01,  1.11s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 00:47:07,220 P574 INFO Train loss: 0.134305\n2025-12-19 00:47:07,220 P574 INFO Evaluation @epoch 1 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.76s/it]\u001b[A\n100%|██████████| 2/2 [00:01<00:00,  1.04it/s]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 00:47:09,191 P574 INFO [Metrics] AUC: 0.796522\n2025-12-19 00:47:09,192 P574 INFO Save best model: monitor(max)=0.796522\n2025-12-19 00:47:09,316 P574 INFO ************ Epoch=1 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:13<00:00,  1.12s/it]\n100%|█████████▉| 439/440 [08:04<00:01,  1.11s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 00:55:14,542 P574 INFO Train loss: 0.047811\n2025-12-19 00:55:14,543 P574 INFO Evaluation @epoch 2 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n100%|██████████| 2/2 [00:01<00:00,  1.02it/s]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 00:55:16,514 P574 INFO [Metrics] AUC: 0.841342\n2025-12-19 00:55:16,515 P574 INFO Save best model: monitor(max)=0.841342\n2025-12-19 00:55:16,673 P574 INFO ************ Epoch=2 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:07<00:00,  1.11s/it]\n100%|█████████▉| 439/440 [08:04<00:01,  1.11s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 01:03:21,684 P574 INFO Train loss: 0.031487\n2025-12-19 01:03:21,685 P574 INFO Evaluation @epoch 3 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.79s/it]\u001b[A\n100%|██████████| 2/2 [00:01<00:00,  1.02it/s]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 01:03:23,654 P574 INFO [Metrics] AUC: 0.847689\n2025-12-19 01:03:23,655 P574 INFO Save best model: monitor(max)=0.847689\n2025-12-19 01:03:23,813 P574 INFO ************ Epoch=3 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:07<00:00,  1.11s/it]\n100%|█████████▉| 439/440 [08:04<00:01,  1.11s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 01:11:29,206 P574 INFO Train loss: 0.022518\n2025-12-19 01:11:29,206 P574 INFO Evaluation @epoch 4 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.80s/it]\u001b[A\n100%|██████████| 2/2 [00:01<00:00,  1.02it/s]\u001b[A\n100%|██████████| 440/440 [08:07<00:00,  1.52s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 01:11:31,187 P574 INFO [Metrics] AUC: 0.846917\n2025-12-19 01:11:31,188 P574 INFO Monitor(max)=0.846917 STOP!\n2025-12-19 01:11:31,188 P574 INFO Reduce learning rate on plateau: 0.000100\n2025-12-19 01:11:31,268 P574 INFO ************ Epoch=4 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:07<00:00,  1.11s/it]\n100%|█████████▉| 439/440 [08:07<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 01:19:38,817 P574 INFO Train loss: 0.011649\n2025-12-19 01:19:38,817 P574 INFO Evaluation @epoch 5 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.90s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.04s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 01:19:40,901 P574 INFO [Metrics] AUC: 0.860382\n2025-12-19 01:19:40,902 P574 INFO Save best model: monitor(max)=0.860382\n2025-12-19 01:19:41,067 P574 INFO ************ Epoch=5 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:09<00:00,  1.11s/it]\n100%|█████████▉| 439/440 [08:14<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 01:27:55,625 P574 INFO Train loss: 0.007928\n2025-12-19 01:27:55,625 P574 INFO Evaluation @epoch 6 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.89s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.03s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 01:27:57,691 P574 INFO [Metrics] AUC: 0.861817\n2025-12-19 01:27:57,692 P574 INFO Save best model: monitor(max)=0.861817\n2025-12-19 01:27:57,852 P574 INFO ************ Epoch=6 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:16<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:12<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 01:36:10,502 P574 INFO Train loss: 0.006166\n2025-12-19 01:36:10,502 P574 INFO Evaluation @epoch 7 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.87s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.02s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 01:36:12,552 P574 INFO [Metrics] AUC: 0.867428\n2025-12-19 01:36:12,553 P574 INFO Save best model: monitor(max)=0.867428\n2025-12-19 01:36:12,712 P574 INFO ************ Epoch=7 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:14<00:00,  1.12s/it]\n100%|█████████▉| 439/440 [08:11<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 01:44:25,105 P574 INFO Train loss: 0.005023\n2025-12-19 01:44:25,105 P574 INFO Evaluation @epoch 8 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.95s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 01:44:27,236 P574 INFO [Metrics] AUC: 0.870116\n2025-12-19 01:44:27,237 P574 INFO Save best model: monitor(max)=0.870116\n2025-12-19 01:44:27,400 P574 INFO ************ Epoch=8 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:14<00:00,  1.12s/it]\n100%|█████████▉| 439/440 [08:11<00:01,  1.12s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 01:52:39,687 P574 INFO Train loss: 0.004237\n2025-12-19 01:52:39,687 P574 INFO Evaluation @epoch 9 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.83s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.01s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 01:52:41,717 P574 INFO [Metrics] AUC: 0.873135\n2025-12-19 01:52:41,718 P574 INFO Save best model: monitor(max)=0.873135\n2025-12-19 01:52:41,897 P574 INFO ************ Epoch=9 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:14<00:00,  1.12s/it]\n100%|█████████▉| 439/440 [08:10<00:01,  1.12s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 02:00:53,317 P574 INFO Train loss: 0.003694\n2025-12-19 02:00:53,318 P574 INFO Evaluation @epoch 10 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.88s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.03s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 02:00:55,393 P574 INFO [Metrics] AUC: 0.874953\n2025-12-19 02:00:55,394 P574 INFO Save best model: monitor(max)=0.874953\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:13<00:00,  1.12s/it]\n  0%|          | 0/440 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 02:00:55,599 P574 INFO ************ Epoch=10 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|█████████▉| 439/440 [08:12<00:01,  1.14s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 02:09:08,159 P574 INFO Train loss: 0.003325\n2025-12-19 02:09:08,160 P574 INFO Evaluation @epoch 11 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.85s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.01s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 02:09:10,194 P574 INFO [Metrics] AUC: 0.877255\n2025-12-19 02:09:10,195 P574 INFO Save best model: monitor(max)=0.877255\n2025-12-19 02:09:10,359 P574 INFO ************ Epoch=11 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:14<00:00,  1.12s/it]\n100%|█████████▉| 439/440 [08:15<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 02:17:26,802 P574 INFO Train loss: 0.003088\n2025-12-19 02:17:26,803 P574 INFO Evaluation @epoch 12 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.90s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.03s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 02:17:28,880 P574 INFO [Metrics] AUC: 0.880030\n2025-12-19 02:17:28,881 P574 INFO Save best model: monitor(max)=0.880030\n2025-12-19 02:17:29,033 P574 INFO ************ Epoch=12 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:18<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:14<00:01,  1.12s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 02:25:44,150 P574 INFO Train loss: 0.002871\n2025-12-19 02:25:44,150 P574 INFO Evaluation @epoch 13 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.91s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.05s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 02:25:46,258 P574 INFO [Metrics] AUC: 0.880710\n2025-12-19 02:25:46,259 P574 INFO Save best model: monitor(max)=0.880710\n2025-12-19 02:25:46,429 P574 INFO ************ Epoch=13 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:17<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:14<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 02:34:01,726 P574 INFO Train loss: 0.002703\n2025-12-19 02:34:01,727 P574 INFO Evaluation @epoch 14 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.86s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.02s/it]\u001b[A\n100%|██████████| 440/440 [08:17<00:00,  1.56s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 02:34:03,780 P574 INFO [Metrics] AUC: 0.880151\n2025-12-19 02:34:03,781 P574 INFO Monitor(max)=0.880151 STOP!\n2025-12-19 02:34:03,781 P574 INFO Reduce learning rate on plateau: 0.000010\n2025-12-19 02:34:03,883 P574 INFO ************ Epoch=14 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:17<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:15<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 02:42:20,370 P574 INFO Train loss: 0.002557\n2025-12-19 02:42:20,370 P574 INFO Evaluation @epoch 15 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.90s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.04s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 02:42:22,462 P574 INFO [Metrics] AUC: 0.881745\n2025-12-19 02:42:22,463 P574 INFO Save best model: monitor(max)=0.881745\n2025-12-19 02:42:22,620 P574 INFO ************ Epoch=15 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:18<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:13<00:01,  1.14s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 02:50:36,993 P574 INFO Train loss: 0.002522\n2025-12-19 02:50:36,993 P574 INFO Evaluation @epoch 16 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.90s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.04s/it]\u001b[A\n100%|██████████| 440/440 [08:16<00:00,  1.57s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 02:50:39,080 P574 INFO [Metrics] AUC: 0.881707\n2025-12-19 02:50:39,081 P574 INFO Monitor(max)=0.881707 STOP!\n2025-12-19 02:50:39,081 P574 INFO Reduce learning rate on plateau: 0.000001\n2025-12-19 02:50:39,165 P574 INFO ************ Epoch=16 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:16<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:13<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 02:58:52,722 P574 INFO Train loss: 0.002497\n2025-12-19 02:58:52,723 P574 INFO Evaluation @epoch 17 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.95s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\u001b[A\n100%|██████████| 440/440 [08:15<00:00,  1.59s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 02:58:54,854 P574 INFO [Metrics] AUC: 0.881615\n2025-12-19 02:58:54,855 P574 INFO Monitor(max)=0.881615 STOP!\n2025-12-19 02:58:54,855 P574 INFO Reduce learning rate on plateau: 0.000001\n2025-12-19 02:58:54,943 P574 INFO ************ Epoch=17 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:15<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:13<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 03:07:09,030 P574 INFO Train loss: 0.002499\n2025-12-19 03:07:09,031 P574 INFO Evaluation @epoch 18 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.92s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.05s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 03:07:11,139 P574 INFO [Metrics] AUC: 0.880920\n2025-12-19 03:07:11,140 P574 INFO Monitor(max)=0.880920 STOP!\n2025-12-19 03:07:11,140 P574 INFO Reduce learning rate on plateau: 0.000001\n2025-12-19 03:07:11,140 P574 INFO ********* Epoch=18 early stop *********\n2025-12-19 03:07:11,227 P574 INFO Training finished.\n2025-12-19 03:07:11,227 P574 INFO Load best model: /kaggle/working/WWW2025_MMCTR_Challenge_repo/checkpoints/MicroLens_1M_x1/DIN_MicroLens_1M_x1_001_9377cbcb.model\n2025-12-19 03:07:11,262 P574 INFO ****** Validation evaluation ******\n","output_type":"stream"},{"name":"stdout","text":"100%|█████████▉| 439/440 [08:16<00:01,  1.13s/it]\n100%|██████████| 2/2 [00:02<00:00,  1.05s/it]\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/kaggle/working/WWW2025_MMCTR_Challenge_repo/run_expid.py\", line 73, in <module>\n    valid_result = model.evaluate(valid_gen)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/fuxictr/pytorch/models/rank_model.py\", line 247, in evaluate\n    val_logs = self.evaluate_metrics(y_true, y_pred, self.validation_metrics, group_id)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/fuxictr/pytorch/models/rank_model.py\", line 264, in evaluate_metrics\n    return evaluate_metrics(y_true, y_pred, metrics, group_id)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/fuxictr/metrics.py\", line 31, in evaluate_metrics\n    return_dict[metric] = log_loss(y_true, y_pred, eps=1e-7)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\", line 196, in wrapper\n    params = func_sig.bind(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/inspect.py\", line 3280, in bind\n    return self._bind(args, kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.12/inspect.py\", line 3269, in _bind\n    raise TypeError(\nTypeError: got an unexpected keyword argument 'eps'\n2025-12-19 03:07:19,499 P1014 INFO FuxiCTR version: 2.3.7\n2025-12-19 03:07:19,499 P1014 INFO Params: {\n    \"accumulation_steps\": \"1\",\n    \"attention_dropout\": \"0.1\",\n    \"attention_hidden_activations\": \"ReLU\",\n    \"attention_hidden_units\": \"[512, 256]\",\n    \"attention_output_activation\": \"None\",\n    \"batch_norm\": \"True\",\n    \"batch_size\": \"8192\",\n    \"data_format\": \"parquet\",\n    \"data_root\": \"/kaggle/working/WWW2025_MMCTR_Challenge_repo/data\",\n    \"dataset_id\": \"MicroLens_1M_x1\",\n    \"debug_mode\": \"False\",\n    \"din_use_softmax\": \"False\",\n    \"dnn_activations\": \"ReLU\",\n    \"dnn_hidden_units\": \"[1024, 512, 256]\",\n    \"early_stop_patience\": \"3\",\n    \"embedding_dim\": \"64\",\n    \"embedding_regularizer\": \"1e-07\",\n    \"epochs\": \"100\",\n    \"eval_steps\": \"None\",\n    \"feature_cols\": \"[{'active': True, 'dtype': 'int', 'name': 'user_id', 'type': 'meta'}, {'active': True, 'dtype': 'int', 'name': 'item_seq', 'type': 'meta'}, {'active': True, 'dtype': 'int', 'name': 'likes_level', 'type': 'categorical', 'vocab_size': 11}, {'active': True, 'dtype': 'int', 'name': 'views_level', 'type': 'categorical', 'vocab_size': 11}, {'active': True, 'dtype': 'int', 'name': 'item_id', 'source': 'item', 'type': 'categorical', 'vocab_size': 91718}, {'active': True, 'dtype': 'int', 'max_len': 5, 'name': 'item_tags', 'source': 'item', 'type': 'sequence', 'vocab_size': 11740}, {'active': True, 'dtype': 'float', 'embedding_dim': 128, 'name': 'item_emb_d128', 'source': 'item', 'type': 'embedding'}]\",\n    \"feature_config\": \"None\",\n    \"feature_specs\": \"None\",\n    \"gpu\": \"0\",\n    \"group_id\": \"user_id\",\n    \"item_info\": \"./data/MicroLens_1M_x1/item_info.parquet\",\n    \"label_col\": \"{'dtype': 'float', 'name': 'label'}\",\n    \"learning_rate\": \"0.001\",\n    \"loss\": \"binary_crossentropy\",\n    \"max_len\": \"64\",\n    \"metrics\": \"['AUC', 'logloss']\",\n    \"model\": \"DIN\",\n    \"model_id\": \"DIN_MicroLens_1M_x1_002_fb68e038\",\n    \"model_root\": \"./checkpoints/\",\n    \"monitor\": \"AUC\",\n    \"monitor_mode\": \"max\",\n    \"net_dropout\": \"0.1\",\n    \"net_regularizer\": \"0\",\n    \"num_workers\": \"3\",\n    \"optimizer\": \"adam\",\n    \"pickle_feature_encoder\": \"True\",\n    \"rebuild_dataset\": \"False\",\n    \"save_best_only\": \"True\",\n    \"seed\": \"20242025\",\n    \"shuffle\": \"True\",\n    \"task\": \"binary_classification\",\n    \"test_data\": \"./data/MicroLens_1M_x1/test.parquet\",\n    \"train_data\": \"./data/MicroLens_1M_x1/train.parquet\",\n    \"use_features\": \"None\",\n    \"valid_data\": \"./data/MicroLens_1M_x1/valid.parquet\",\n    \"verbose\": \"1\"\n}\n2025-12-19 03:07:19,500 P1014 INFO Set up feature processor...\n2025-12-19 03:07:19,501 P1014 INFO Fit feature processor...\n2025-12-19 03:07:19,501 P1014 INFO Processing column: {'active': True, 'dtype': 'int', 'name': 'user_id', 'type': 'meta'}\n2025-12-19 03:07:19,501 P1014 INFO Processing column: {'active': True, 'dtype': 'int', 'name': 'item_seq', 'type': 'meta'}\n2025-12-19 03:07:19,501 P1014 INFO Processing column: {'active': True, 'dtype': 'int', 'name': 'likes_level', 'type': 'categorical', 'vocab_size': 11}\n2025-12-19 03:07:19,501 P1014 INFO Processing column: {'active': True, 'dtype': 'int', 'name': 'views_level', 'type': 'categorical', 'vocab_size': 11}\n2025-12-19 03:07:19,501 P1014 INFO Processing column: {'active': True, 'dtype': 'int', 'name': 'item_id', 'source': 'item', 'type': 'categorical', 'vocab_size': 91718}\n2025-12-19 03:07:19,532 P1014 INFO Processing column: {'active': True, 'dtype': 'int', 'max_len': 5, 'name': 'item_tags', 'source': 'item', 'type': 'sequence', 'vocab_size': 11740}\n2025-12-19 03:07:19,535 P1014 INFO Processing column: {'active': True, 'dtype': 'float', 'embedding_dim': 128, 'name': 'item_emb_d128', 'source': 'item', 'type': 'embedding'}\n2025-12-19 03:07:19,535 P1014 INFO Set column index...\n2025-12-19 03:07:19,535 P1014 INFO Save feature_map to json: /kaggle/working/WWW2025_MMCTR_Challenge_repo/data/MicroLens_1M_x1/feature_map.json\n2025-12-19 03:07:19,536 P1014 INFO Pickle feature_encode: /kaggle/working/WWW2025_MMCTR_Challenge_repo/data/MicroLens_1M_x1/feature_processor.pkl\n2025-12-19 03:07:19,541 P1014 INFO Save feature_vocab to json: /kaggle/working/WWW2025_MMCTR_Challenge_repo/data/MicroLens_1M_x1/feature_vocab.json\n2025-12-19 03:07:19,684 P1014 INFO Set feature processor done.\n2025-12-19 03:07:19,684 P1014 INFO Load feature_map from json: /kaggle/working/WWW2025_MMCTR_Challenge_repo/data/MicroLens_1M_x1/feature_map.json\n2025-12-19 03:07:19,684 P1014 INFO Set column index...\n2025-12-19 03:07:19,685 P1014 INFO Feature specs: {\n    \"item_emb_d128\": \"{'source': 'item', 'type': 'embedding', 'embedding_dim': 128}\",\n    \"item_id\": \"{'source': 'item', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 91718}\",\n    \"item_seq\": \"{'type': 'meta'}\",\n    \"item_tags\": \"{'source': 'item', 'type': 'sequence', 'feature_encoder': 'layers.MaskedAveragePooling()', 'padding_idx': 0, 'max_len': 5, 'vocab_size': 11740}\",\n    \"likes_level\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 11}\",\n    \"user_id\": \"{'type': 'meta'}\",\n    \"views_level\": \"{'source': '', 'type': 'categorical', 'padding_idx': 0, 'vocab_size': 11}\"\n}\n2025-12-19 03:07:21,066 P1014 INFO Total number of parameters: 8611842.\n2025-12-19 03:07:21,066 P1014 INFO Loading datasets...\n2025-12-19 03:07:32,060 P1014 INFO Train samples: total/3600000, blocks/1\n2025-12-19 03:07:32,853 P1014 INFO Validation samples: total/10000, blocks/1\n2025-12-19 03:07:32,854 P1014 INFO Loading train and validation data done.\n2025-12-19 03:07:32,854 P1014 INFO Start training: 440 batches/epoch\n2025-12-19 03:07:32,854 P1014 INFO ************ Epoch=1 start ************\n","output_type":"stream"},{"name":"stdout","text":"100%|█████████▉| 439/440 [08:17<00:01,  1.12s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 03:15:50,667 P1014 INFO Train loss: 0.134859\n2025-12-19 03:15:50,668 P1014 INFO Evaluation @epoch 1 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.87s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.02s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 03:15:52,723 P1014 INFO [Metrics] AUC: 0.528969\n2025-12-19 03:15:52,724 P1014 INFO Save best model: monitor(max)=0.528969\n2025-12-19 03:15:52,853 P1014 INFO ************ Epoch=1 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:19<00:00,  1.14s/it]\n100%|█████████▉| 439/440 [08:15<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 03:24:08,857 P1014 INFO Train loss: 0.046259\n2025-12-19 03:24:08,857 P1014 INFO Evaluation @epoch 2 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.94s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\u001b[A\n100%|██████████| 440/440 [08:18<00:00,  1.59s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 03:24:10,982 P1014 INFO [Metrics] AUC: 0.526522\n2025-12-19 03:24:10,982 P1014 INFO Monitor(max)=0.526522 STOP!\n2025-12-19 03:24:10,983 P1014 INFO Reduce learning rate on plateau: 0.000100\n2025-12-19 03:24:11,072 P1014 INFO ************ Epoch=2 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:18<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:16<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 03:32:27,911 P1014 INFO Train loss: 0.023120\n2025-12-19 03:32:27,911 P1014 INFO Evaluation @epoch 3 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.88s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.03s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 03:32:29,987 P1014 INFO [Metrics] AUC: 0.843562\n2025-12-19 03:32:29,988 P1014 INFO Save best model: monitor(max)=0.843562\n2025-12-19 03:32:30,179 P1014 INFO ************ Epoch=3 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:19<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:17<00:01,  1.14s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 03:40:48,631 P1014 INFO Train loss: 0.016761\n2025-12-19 03:40:48,631 P1014 INFO Evaluation @epoch 4 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.98s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.08s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 03:40:50,799 P1014 INFO [Metrics] AUC: 0.847007\n2025-12-19 03:40:50,800 P1014 INFO Save best model: monitor(max)=0.847007\n2025-12-19 03:40:50,983 P1014 INFO ************ Epoch=4 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:20<00:00,  1.14s/it]\n100%|█████████▉| 439/440 [08:15<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 03:49:06,811 P1014 INFO Train loss: 0.012936\n2025-12-19 03:49:06,811 P1014 INFO Evaluation @epoch 5 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.92s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.05s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 03:49:08,917 P1014 INFO [Metrics] AUC: 0.849926\n2025-12-19 03:49:08,918 P1014 INFO Save best model: monitor(max)=0.849926\n2025-12-19 03:49:09,090 P1014 INFO ************ Epoch=5 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:18<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:17<00:01,  1.14s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 03:57:26,982 P1014 INFO Train loss: 0.009920\n2025-12-19 03:57:26,982 P1014 INFO Evaluation @epoch 6 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.97s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.07s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 03:57:29,130 P1014 INFO [Metrics] AUC: 0.853918\n2025-12-19 03:57:29,131 P1014 INFO Save best model: monitor(max)=0.853918\n2025-12-19 03:57:29,310 P1014 INFO ************ Epoch=6 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:20<00:00,  1.14s/it]\n100%|█████████▉| 439/440 [08:14<00:01,  1.12s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 04:05:44,576 P1014 INFO Train loss: 0.007411\n2025-12-19 04:05:44,576 P1014 INFO Evaluation @epoch 7 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.92s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.05s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 04:05:46,684 P1014 INFO [Metrics] AUC: 0.857113\n2025-12-19 04:05:46,684 P1014 INFO Save best model: monitor(max)=0.857113\n2025-12-19 04:05:46,849 P1014 INFO ************ Epoch=7 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:17<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:15<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 04:14:02,835 P1014 INFO Train loss: 0.005345\n2025-12-19 04:14:02,835 P1014 INFO Evaluation @epoch 8 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.84s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.00s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 04:14:04,855 P1014 INFO [Metrics] AUC: 0.859197\n2025-12-19 04:14:04,856 P1014 INFO Save best model: monitor(max)=0.859197\n2025-12-19 04:14:05,014 P1014 INFO ************ Epoch=8 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:18<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:12<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 04:22:17,982 P1014 INFO Train loss: 0.003731\n2025-12-19 04:22:17,983 P1014 INFO Evaluation @epoch 9 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.88s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.03s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 04:22:20,045 P1014 INFO [Metrics] AUC: 0.865163\n2025-12-19 04:22:20,046 P1014 INFO Save best model: monitor(max)=0.865163\n2025-12-19 04:22:20,218 P1014 INFO ************ Epoch=9 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:15<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:12<00:01,  1.12s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 04:30:33,377 P1014 INFO Train loss: 0.002572\n2025-12-19 04:30:33,377 P1014 INFO Evaluation @epoch 10 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.88s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.03s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 04:30:35,454 P1014 INFO [Metrics] AUC: 0.869673\n2025-12-19 04:30:35,455 P1014 INFO Save best model: monitor(max)=0.869673\n2025-12-19 04:30:35,634 P1014 INFO ************ Epoch=10 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:15<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:11<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 04:38:48,103 P1014 INFO Train loss: 0.001781\n2025-12-19 04:38:48,103 P1014 INFO Evaluation @epoch 11 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.87s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.03s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 04:38:50,175 P1014 INFO [Metrics] AUC: 0.869905\n2025-12-19 04:38:50,176 P1014 INFO Save best model: monitor(max)=0.869905\n2025-12-19 04:38:50,336 P1014 INFO ************ Epoch=11 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:14<00:00,  1.12s/it]\n100%|█████████▉| 439/440 [08:15<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 04:47:06,051 P1014 INFO Train loss: 0.001322\n2025-12-19 04:47:06,052 P1014 INFO Evaluation @epoch 12 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.86s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.02s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 04:47:08,099 P1014 INFO [Metrics] AUC: 0.876285\n2025-12-19 04:47:08,100 P1014 INFO Save best model: monitor(max)=0.876285\n2025-12-19 04:47:08,271 P1014 INFO ************ Epoch=12 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:17<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:15<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 04:55:23,893 P1014 INFO Train loss: 0.001040\n2025-12-19 04:55:23,894 P1014 INFO Evaluation @epoch 13 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.85s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.01s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 04:55:25,932 P1014 INFO [Metrics] AUC: 0.877955\n2025-12-19 04:55:25,933 P1014 INFO Save best model: monitor(max)=0.877955\n2025-12-19 04:55:26,090 P1014 INFO ************ Epoch=13 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:17<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:14<00:01,  1.14s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 05:03:40,693 P1014 INFO Train loss: 0.000825\n2025-12-19 05:03:40,694 P1014 INFO Evaluation @epoch 14 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.94s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 05:03:42,823 P1014 INFO [Metrics] AUC: 0.878981\n2025-12-19 05:03:42,823 P1014 INFO Save best model: monitor(max)=0.878981\n2025-12-19 05:03:43,000 P1014 INFO ************ Epoch=14 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:16<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:14<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 05:11:57,610 P1014 INFO Train loss: 0.000710\n2025-12-19 05:11:57,610 P1014 INFO Evaluation @epoch 15 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.88s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.03s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 05:11:59,677 P1014 INFO [Metrics] AUC: 0.880356\n2025-12-19 05:11:59,678 P1014 INFO Save best model: monitor(max)=0.880356\n2025-12-19 05:11:59,837 P1014 INFO ************ Epoch=15 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:16<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:15<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 05:20:16,254 P1014 INFO Train loss: 0.000656\n2025-12-19 05:20:16,254 P1014 INFO Evaluation @epoch 16 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.90s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.04s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 05:20:18,356 P1014 INFO [Metrics] AUC: 0.881827\n2025-12-19 05:20:18,357 P1014 INFO Save best model: monitor(max)=0.881827\n2025-12-19 05:20:18,522 P1014 INFO ************ Epoch=16 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:18<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:14<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 05:28:33,608 P1014 INFO Train loss: 0.000614\n2025-12-19 05:28:33,609 P1014 INFO Evaluation @epoch 17 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.92s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.04s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 05:28:35,707 P1014 INFO [Metrics] AUC: 0.885999\n2025-12-19 05:28:35,708 P1014 INFO Save best model: monitor(max)=0.885999\n2025-12-19 05:28:35,908 P1014 INFO ************ Epoch=17 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:17<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:14<00:01,  1.14s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 05:36:51,247 P1014 INFO Train loss: 0.000550\n2025-12-19 05:36:51,247 P1014 INFO Evaluation @epoch 18 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.98s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.08s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 05:36:53,414 P1014 INFO [Metrics] AUC: 0.887580\n2025-12-19 05:36:53,415 P1014 INFO Save best model: monitor(max)=0.887580\n2025-12-19 05:36:53,599 P1014 INFO ************ Epoch=18 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:17<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:15<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 05:45:09,209 P1014 INFO Train loss: 0.000544\n2025-12-19 05:45:09,209 P1014 INFO Evaluation @epoch 19 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:02<00:02,  2.20s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.20s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 05:45:11,615 P1014 INFO [Metrics] AUC: 0.888872\n2025-12-19 05:45:11,616 P1014 INFO Save best model: monitor(max)=0.888872\n2025-12-19 05:45:11,803 P1014 INFO ************ Epoch=19 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:18<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:15<00:01,  1.14s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 05:53:27,327 P1014 INFO Train loss: 0.000522\n2025-12-19 05:53:27,328 P1014 INFO Evaluation @epoch 20 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.94s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.05s/it]\u001b[A\n100%|██████████| 440/440 [08:17<00:00,  1.59s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 05:53:29,447 P1014 INFO [Metrics] AUC: 0.888250\n2025-12-19 05:53:29,448 P1014 INFO Monitor(max)=0.888250 STOP!\n2025-12-19 05:53:29,448 P1014 INFO Reduce learning rate on plateau: 0.000010\n2025-12-19 05:53:29,549 P1014 INFO ************ Epoch=20 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:17<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:15<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 06:01:45,506 P1014 INFO Train loss: 0.000400\n2025-12-19 06:01:45,506 P1014 INFO Evaluation @epoch 21 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.92s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.05s/it]\u001b[A\n100%|██████████| 440/440 [08:18<00:00,  1.57s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 06:01:47,609 P1014 INFO [Metrics] AUC: 0.888726\n2025-12-19 06:01:47,610 P1014 INFO Monitor(max)=0.888726 STOP!\n2025-12-19 06:01:47,610 P1014 INFO Reduce learning rate on plateau: 0.000001\n2025-12-19 06:01:47,689 P1014 INFO ************ Epoch=21 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:18<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:14<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 06:10:02,454 P1014 INFO Train loss: 0.000337\n2025-12-19 06:10:02,455 P1014 INFO Evaluation @epoch 22 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.93s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 06:10:04,580 P1014 INFO [Metrics] AUC: 0.889041\n2025-12-19 06:10:04,581 P1014 INFO Save best model: monitor(max)=0.889041\n2025-12-19 06:10:04,745 P1014 INFO ************ Epoch=22 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:17<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:15<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 06:18:20,648 P1014 INFO Train loss: 0.000326\n2025-12-19 06:18:20,648 P1014 INFO Evaluation @epoch 23 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.93s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\u001b[A\n","output_type":"stream"},{"name":"stderr","text":"2025-12-19 06:18:22,777 P1014 INFO [Metrics] AUC: 0.889125\n2025-12-19 06:18:22,778 P1014 INFO Save best model: monitor(max)=0.889125\n2025-12-19 06:18:22,961 P1014 INFO ************ Epoch=23 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:18<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:15<00:01,  1.13s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 06:26:38,947 P1014 INFO Train loss: 0.000325\n2025-12-19 06:26:38,948 P1014 INFO Evaluation @epoch 24 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.93s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.05s/it]\u001b[A\n100%|██████████| 440/440 [08:18<00:00,  1.58s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 06:26:41,062 P1014 INFO [Metrics] AUC: 0.888799\n2025-12-19 06:26:41,063 P1014 INFO Monitor(max)=0.888799 STOP!\n2025-12-19 06:26:41,063 P1014 INFO Reduce learning rate on plateau: 0.000001\n2025-12-19 06:26:41,165 P1014 INFO ************ Epoch=24 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:18<00:00,  1.13s/it]\n100%|█████████▉| 439/440 [08:14<00:01,  1.12s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 06:34:55,725 P1014 INFO Train loss: 0.000323\n2025-12-19 06:34:55,725 P1014 INFO Evaluation @epoch 25 - batch 440: \n","output_type":"stream"},{"name":"stdout","text":"\n  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n 50%|█████     | 1/2 [00:01<00:01,  1.90s/it]\u001b[A\n100%|██████████| 2/2 [00:02<00:00,  1.04s/it]\u001b[A\n100%|██████████| 440/440 [08:16<00:00,  1.56s/it]","output_type":"stream"},{"name":"stderr","text":"2025-12-19 06:34:57,821 P1014 INFO [Metrics] AUC: 0.888977\n2025-12-19 06:34:57,822 P1014 INFO Monitor(max)=0.888977 STOP!\n2025-12-19 06:34:57,822 P1014 INFO Reduce learning rate on plateau: 0.000001\n2025-12-19 06:34:57,907 P1014 INFO ************ Epoch=25 end ************\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 440/440 [08:16<00:00,  1.13s/it]\n 55%|█████▌    | 243/440 [04:36<03:43,  1.14s/it]\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/kaggle/working/WWW2025_MMCTR_Challenge_repo/run_expid.py\", line 70, in <module>\n    model.fit(train_gen, validation_data=valid_gen, **params)\n  File \"/usr/local/lib/python3.12/dist-packages/fuxictr/pytorch/models/rank_model.py\", line 160, in fit\n    self.train_epoch(data_generator)\n  File \"/usr/local/lib/python3.12/dist-packages/fuxictr/pytorch/models/rank_model.py\", line 218, in train_epoch\n    loss = self.train_step(batch_data)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/working/WWW2025_MMCTR_Challenge_repo/src/DIN.py\", line 132, in train_step\n    loss.backward()\n  File \"/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\", line 647, in backward\n    torch.autograd.backward(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\", line 354, in backward\n    _engine_run_backward(\n  File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\", line 829, in _engine_run_backward\n    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`\n","output_type":"stream"},{"name":"stdout","text":"Enumerate all tuner configurations done.\n✅ finished with code: 0\n\n📦 Derniers éléments checkpoints:\n - checkpoints/MicroLens_1M_x1/DIN_MicroLens_1M_x1_002_fb68e038.log\n - checkpoints/MicroLens_1M_x1/DIN_MicroLens_1M_x1_002_fb68e038.model\n - checkpoints/MicroLens_1M_x1\n - checkpoints/MicroLens_1M_x1/DIN_MicroLens_1M_x1_001_9377cbcb.log\n - checkpoints/MicroLens_1M_x1/DIN_MicroLens_1M_x1_001_9377cbcb.model\n","output_type":"stream"}],"execution_count":28},{"id":"4a91f54f","cell_type":"markdown","source":"# 10) Inference + création du fichier submission\nOn cherche le checkpoint le plus récent, puis on prédit sur test et on écrit `prediction.csv`.\n","metadata":{}},{"id":"0c8e65c5","cell_type":"code","source":"from pathlib import Path\nimport yaml\n\n# 1) Chemins de base\nREPO_DIR = Path(\"/kaggle/working/WWW2025_MMCTR_Challenge_repo\")\nCONFIG_DIR = REPO_DIR / \"config\"\nCUSTOM_DIR = CONFIG_DIR / \"CUSTOM\"\n\nEXP_ID = \"DIN_MicroLens_1M_x1_001_9377cbcb\"  # ton meilleur modèle\nprint(f\"📁 REPO_DIR: {REPO_DIR}\")\nprint(f\"🏷️ EXP_ID: {EXP_ID}\")\nprint(f\"📂 CUSTOM_DIR: {CUSTOM_DIR}\")\n\n# 2) Lister les YAML dispo dans config/CUSTOM\nyaml_files = sorted(CUSTOM_DIR.glob(\"*.yaml\"))\nprint(\"✅ YAML trouvés dans config/CUSTOM :\")\nfor y in yaml_files:\n    print(\"   -\", y.name)\n\n# 3) Chercher le bon fichier : DCNv2_MicroLens_1M_x1_task12_aucboost.yaml\nCONFIG_PATH = None\nfor y in yaml_files:\n    if \"DCNv2_MicroLens_1M_x1_task12_aucboost.yaml\" in str(y):\n        CONFIG_PATH = y\n        break\n\n# Si tu veux être plus souple, tu peux utiliser juste \"DCNv2_MicroLens_1M_x1_task12_aucboost\"\n# for y in yaml_files:\n#     if \"DCNv2_MicroLens_1M_x1_task12_aucboost\" in y.name:\n#         CONFIG_PATH = y\n#         break\n\nassert CONFIG_PATH is not None, \"❌ Impossible de trouver le fichier DCNv2_MicroLens_1M_x1_task12_aucboost.yaml dans config/CUSTOM\"\nassert CONFIG_PATH.exists(), f\"❌ Config introuvable sur le disque : {CONFIG_PATH}\"\n\nprint(f\"📄 CONFIG_PATH sélectionné : {CONFIG_PATH}\")\n\n# 4) Charger le YAML dans un dict Python\nwith open(CONFIG_PATH, \"r\") as f:\n    config = yaml.safe_load(f)\n\nprint(\"✅ YAML chargé. Clés au niveau racine :\")\nprint(list(config.keys()))\n\n# Si tu as besoin plus tard :\n# model_params   = config.get(\"model\", {})\n# dataset_params = config.get(\"dataset\", {})\n# training_params = config.get(\"training\", {})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T08:07:55.007121Z","iopub.execute_input":"2025-12-19T08:07:55.007844Z","iopub.status.idle":"2025-12-19T08:07:55.025954Z","shell.execute_reply.started":"2025-12-19T08:07:55.007812Z","shell.execute_reply":"2025-12-19T08:07:55.025114Z"}},"outputs":[{"name":"stdout","text":"📁 REPO_DIR: /kaggle/working/WWW2025_MMCTR_Challenge_repo\n🏷️ EXP_ID: DIN_MicroLens_1M_x1_001_9377cbcb\n📂 CUSTOM_DIR: /kaggle/working/WWW2025_MMCTR_Challenge_repo/config/CUSTOM\n✅ YAML trouvés dans config/CUSTOM :\n   - DCNv2_MicroLens_1M_x1_task12_aucboost.yaml\n   - DIN_MicroLens_1M_x1_task1_aucboost.yaml\n📄 CONFIG_PATH sélectionné : /kaggle/working/WWW2025_MMCTR_Challenge_repo/config/CUSTOM/DCNv2_MicroLens_1M_x1_task12_aucboost.yaml\n✅ YAML chargé. Clés au niveau racine :\n['base_config', 'base_expid', 'dataset_id', 'dataset_config', 'tuner_space', 'model', 'tuner_params']\n","output_type":"stream"}],"execution_count":38},{"id":"a5c32b88-1510-4ef2-9200-5cd91fd49eec","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pathlib import Path\n\n# ==========================\n# 1. Paths de base\n# ==========================\nREPO_DIR = Path(\"/kaggle/working/WWW2025_MMCTR_Challenge_repo\")\nDATA_DIR = REPO_DIR / \"data\" / \"MicroLens_1M_x1\"\n\nprint(\"📁 REPO_DIR:\", REPO_DIR)\nprint(\"📁 DATA_DIR:\", DATA_DIR)\n\n# Candidats possibles pour le fichier train\ntrain_candidates = [\n    DATA_DIR / \"train.parquet\",\n    DATA_DIR / \"MicroLens_1M_x1_train.parquet\"\n]\n\nTRAIN_PATH = None\nfor p in train_candidates:\n    if p.exists():\n        TRAIN_PATH = p\n        break\n\nif TRAIN_PATH is None:\n    raise FileNotFoundError(\n        f\"Aucun fichier train.parquet trouvé dans {DATA_DIR}\\n\"\n        \"➡️ Adapte manuellement TRAIN_PATH en regardant le contenu du dossier.\"\n    )\n\nTEST_PATH = DATA_DIR / \"test.parquet\"\nif not TEST_PATH.exists():\n    raise FileNotFoundError(f\"Fichier test.parquet introuvable: {TEST_PATH}\")\n\nprint(\"✅ TRAIN_PATH:\", TRAIN_PATH)\nprint(\"✅ TEST_PATH:\", TEST_PATH)\n\n# ==========================\n# 2. Chargement des données\n# ==========================\ntrain_df = pd.read_parquet(TRAIN_PATH)\ntest_df = pd.read_parquet(TEST_PATH)\n\nprint(\"✅ train shape:\", train_df.shape)\nprint(\"✅ test shape:\", test_df.shape)\nprint(\"📎 Colonnes train:\", list(train_df.columns))\nprint(\"📎 Colonnes test :\", list(test_df.columns))\n\n# ==========================\n# 3. Détection automatique des colonnes\n# ==========================\n\n# 3.1 Colonne label\nlabel_candidates = [\"label\", \"target\", \"click\", \"y\"]\nLABEL_COL = None\nfor c in label_candidates:\n    if c in train_df.columns:\n        LABEL_COL = c\n        break\n\nif LABEL_COL is None:\n    raise ValueError(\n        \"Impossible de trouver la colonne label. \"\n        f\"Colonnes disponibles dans train: {list(train_df.columns)}\\n\"\n        \"➡️ Mets le vrai nom dans LABEL_COL.\"\n    )\n\nprint(f\"✅ Colonne label détectée: {LABEL_COL}\")\n\n# 3.2 Colonne item\nitem_candidates = [\"item_id\", \"item\", \"product_id\"]\nITEM_COL = None\nfor c in item_candidates:\n    if c in train_df.columns:\n        ITEM_COL = c\n        break\n\nif ITEM_COL is None:\n    raise ValueError(\n        \"Impossible de trouver la colonne item.\\n\"\n        \"➡️ Mets manuellement le nom dans ITEM_COL (ex: 'item_id').\"\n    )\n\nprint(f\"✅ Colonne item détectée: {ITEM_COL}\")\n\n# 3.3 Colonne id pour la soumission (optionnel mais pratique)\nid_candidates = [\"sample_id\", \"id\", \"row_id\"]\nID_COL = None\nfor c in id_candidates:\n    if c in test_df.columns:\n        ID_COL = c\n        break\n\nif ID_COL is not None:\n    print(f\"✅ Colonne id détectée pour la soumission: {ID_COL}\")\nelse:\n    print(\"ℹ️ Aucune colonne id explicite détectée. \"\n          \"On utilisera juste l'ordre des lignes pour prediction.csv.\")\n\n# ==========================\n# 4. Calcul de la popularité (CTR)\n# ==========================\nprint(\"📊 Calcul des CTR par item...\")\n\ngroup = train_df.groupby(ITEM_COL)[LABEL_COL].agg([\"sum\", \"count\"]).reset_index()\ngroup.rename(columns={\"sum\": \"clicks\", \"count\": \"impressions\"}, inplace=True)\n\n# CTR lissé (Laplace)\ngroup[\"ctr\"] = (group[\"clicks\"] + 1.0) / (group[\"impressions\"] + 2.0)\n\nprint(\"✅ Exemple de stats item :\")\nprint(group.head())\n\n# CTR global au cas où certains items de test n'apparaissent pas dans train\nglobal_ctr = (train_df[LABEL_COL].sum() + 1.0) / (len(train_df) + 2.0)\nprint(f\"🌍 CTR global (fallback) : {global_ctr:.6f}\")\n\n# ==========================\n# 5. Jointure sur le test\n# ==========================\nprint(\"🔗 Merge test_df avec les CTR des items...\")\n\ntest_with_ctr = test_df.merge(group[[ITEM_COL, \"ctr\"]],\n                              on=ITEM_COL,\n                              how=\"left\")\n\nmissing = test_with_ctr[\"ctr\"].isna().sum()\nprint(f\"ℹ️ Items de test sans stats dans le train : {missing}\")\n\ntest_with_ctr[\"ctr\"].fillna(global_ctr, inplace=True)\n\n# ==========================\n# 6. Construction du DataFrame de soumission\n# ==========================\nif ID_COL is not None:\n    submission = pd.DataFrame({\n        ID_COL: test_with_ctr[ID_COL],\n        \"prediction\": test_with_ctr[\"ctr\"].astype(float)\n    })\nelse:\n    # Pas d'id explicite -> juste une colonne 'prediction'\n    submission = pd.DataFrame({\n        \"prediction\": test_with_ctr[\"ctr\"].astype(float)\n    })\n\nOUT_PATH = Path(\"/kaggle/working/prediction.csv\")\nsubmission.to_csv(OUT_PATH, index=False)\n\nprint(\"✅ prediction.csv généré :\", OUT_PATH)\nprint(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T08:24:31.515657Z","iopub.execute_input":"2025-12-19T08:24:31.516169Z","iopub.status.idle":"2025-12-19T08:24:40.851787Z","shell.execute_reply.started":"2025-12-19T08:24:31.516138Z","shell.execute_reply":"2025-12-19T08:24:40.850945Z"}},"outputs":[{"name":"stdout","text":"📁 REPO_DIR: /kaggle/working/WWW2025_MMCTR_Challenge_repo\n📁 DATA_DIR: /kaggle/working/WWW2025_MMCTR_Challenge_repo/data/MicroLens_1M_x1\n✅ TRAIN_PATH: /kaggle/working/WWW2025_MMCTR_Challenge_repo/data/MicroLens_1M_x1/train.parquet\n✅ TEST_PATH: /kaggle/working/WWW2025_MMCTR_Challenge_repo/data/MicroLens_1M_x1/test.parquet\n✅ train shape: (3600000, 6)\n✅ test shape: (379142, 6)\n📎 Colonnes train: ['user_id', 'item_seq', 'item_id', 'likes_level', 'views_level', 'label']\n📎 Colonnes test : ['ID', 'user_id', 'item_seq', 'item_id', 'likes_level', 'views_level']\n✅ Colonne label détectée: label\n✅ Colonne item détectée: item_id\nℹ️ Aucune colonne id explicite détectée. On utilisera juste l'ordre des lignes pour prediction.csv.\n📊 Calcul des CTR par item...\n✅ Exemple de stats item :\n   item_id  clicks  impressions       ctr\n0        1       1          203  0.009756\n1        2       1          216  0.009174\n2        3       1          183  0.010811\n3        4      17          193  0.092308\n4        5       3          198  0.020000\n🌍 CTR global (fallback) : 0.250000\n🔗 Merge test_df avec les CTR des items...\nℹ️ Items de test sans stats dans le train : 7251\n✅ prediction.csv généré : /kaggle/working/prediction.csv\n   prediction\n0    0.857143\n1    0.982456\n2    0.857143\n3    0.075000\n4    0.010753\n","output_type":"stream"}],"execution_count":39},{"id":"032e817c-b912-4dd3-94dc-9e39f40bbd63","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom pathlib import Path\n\n# ==========================\n# 1. Paths de base\n# ==========================\nREPO_DIR = Path(\"/kaggle/working/WWW2025_MMCTR_Challenge_repo\")\nDATA_DIR = REPO_DIR / \"data\" / \"MicroLens_1M_x1\"\n\nTRAIN_PATH = DATA_DIR / \"train.parquet\"\nTEST_PATH  = DATA_DIR / \"test.parquet\"\n\nprint(\"📁 REPO_DIR:\", REPO_DIR)\nprint(\"📁 DATA_DIR:\", DATA_DIR)\nprint(\"✅ TRAIN_PATH:\", TRAIN_PATH)\nprint(\"✅ TEST_PATH :\", TEST_PATH)\n\n# ==========================\n# 2. Chargement\n# ==========================\ntrain_df = pd.read_parquet(TRAIN_PATH)\ntest_df  = pd.read_parquet(TEST_PATH)\n\nprint(\"✅ train shape:\", train_df.shape)\nprint(\"✅ test shape :\", test_df.shape)\nprint(\"📎 Colonnes train:\", list(train_df.columns))\nprint(\"📎 Colonnes test :\", list(test_df.columns))\n\n# On sait déjà, d'après ton log :\nLABEL_COL = \"label\"\nITEM_COL  = \"item_id\"\nID_COL    = \"ID\"        # colonne ID imposée par le challenge\n\n# ==========================\n# 3. CTR baseline par item\n# ==========================\nprint(\"📊 Calcul CTR par item...\")\n\ngroup = (\n    train_df\n    .groupby(ITEM_COL)[LABEL_COL]\n    .agg([\"sum\", \"count\"])\n    .reset_index()\n    .rename(columns={\"sum\": \"clicks\", \"count\": \"impressions\"})\n)\n\n# Lissage Laplace pour éviter 0/1 extrêmes\ngroup[\"ctr\"] = (group[\"clicks\"] + 1.0) / (group[\"impressions\"] + 2.0)\n\nprint(\"✅ Exemple stats item :\")\nprint(group.head())\n\n# CTR global si item du test jamais vu dans train\nglobal_ctr = (train_df[LABEL_COL].sum() + 1.0) / (len(train_df) + 2.0)\nprint(f\"🌍 CTR global fallback : {global_ctr:.6f}\")\n\n# ==========================\n# 4. Join avec le test\n# ==========================\nprint(\"🔗 Merge test + CTR...\")\n\ntest_with_ctr = test_df.merge(\n    group[[ITEM_COL, \"ctr\"]],\n    on=ITEM_COL,\n    how=\"left\"\n)\n\nmissing = test_with_ctr[\"ctr\"].isna().sum()\nprint(f\"ℹ️ Items test sans stats dans train : {missing}\")\n\ntest_with_ctr[\"ctr\"].fillna(global_ctr, inplace=True)\n\n# ==========================\n# 5. Construire prediction.csv\n# ==========================\n# Ici on participe à Task2 -> colonnes: ID, Task2\nsubmission = pd.DataFrame({\n    \"ID\": test_with_ctr[ID_COL],\n    \"Task2\": test_with_ctr[\"ctr\"].astype(float)\n})\n\nOUT_PATH = Path(\"/kaggle/working/prediction-task2.csv\")\nsubmission.to_csv(OUT_PATH, index=False)\n\nprint(\"✅ prediction.csv généré :\", OUT_PATH)\nprint(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T08:30:57.962299Z","iopub.execute_input":"2025-12-19T08:30:57.962699Z","iopub.status.idle":"2025-12-19T08:31:07.587642Z","shell.execute_reply.started":"2025-12-19T08:30:57.962672Z","shell.execute_reply":"2025-12-19T08:31:07.586836Z"}},"outputs":[{"name":"stdout","text":"📁 REPO_DIR: /kaggle/working/WWW2025_MMCTR_Challenge_repo\n📁 DATA_DIR: /kaggle/working/WWW2025_MMCTR_Challenge_repo/data/MicroLens_1M_x1\n✅ TRAIN_PATH: /kaggle/working/WWW2025_MMCTR_Challenge_repo/data/MicroLens_1M_x1/train.parquet\n✅ TEST_PATH : /kaggle/working/WWW2025_MMCTR_Challenge_repo/data/MicroLens_1M_x1/test.parquet\n✅ train shape: (3600000, 6)\n✅ test shape : (379142, 6)\n📎 Colonnes train: ['user_id', 'item_seq', 'item_id', 'likes_level', 'views_level', 'label']\n📎 Colonnes test : ['ID', 'user_id', 'item_seq', 'item_id', 'likes_level', 'views_level']\n📊 Calcul CTR par item...\n✅ Exemple stats item :\n   item_id  clicks  impressions       ctr\n0        1       1          203  0.009756\n1        2       1          216  0.009174\n2        3       1          183  0.010811\n3        4      17          193  0.092308\n4        5       3          198  0.020000\n🌍 CTR global fallback : 0.250000\n🔗 Merge test + CTR...\nℹ️ Items test sans stats dans train : 7251\n✅ prediction.csv généré : /kaggle/working/prediction-task2.csv\n   ID     Task2\n0   0  0.857143\n1   1  0.982456\n2   2  0.857143\n3   3  0.075000\n4   4  0.010753\n","output_type":"stream"}],"execution_count":40},{"id":"b0792518-8f7c-4931-b649-358b1f2ae758","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}